---
title: "STAT 434 Final Project"
author: "Emma Barton & Ryan Vosbigian"
date: "6/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Introduction

Understanding species and identifying potential for endangerment and extinction is essential to protecting species and biodiversity. However, it is difficult to monitor and track every species and their individual risks. The International Union for Conservation of Nature (2020) maintains a list of the status of all known species, but there are many that are still unknown, due to lack of research focused on those species. The status outlined by the IUCN Redlist are in order of lowest to highest risk of endangerement and extinction: least concern, near threatened, vulnerable, endangered, highly endangered, extinct in the wild, extinct. The IUCN lists the undetermined statuses as unknown.

While many individual species have not been studied enough to determine status, there are species databases that have compiled information on all bird and mammal species. Elton Traits, which was created by Wilman and colleagues (2014), has compiled diet and foraging variables for all currently existing birds and mammals and used interpolation based on similar traits and phylogentic relationships to fill in for missing traits.

These foraging and diet characteristics could help predict status, because species that share similar food sources or foraging strageties could be influenced similarly by human activities and other pressures. Alternatively, decreased competition between similar species if one becomes endangered could lead to more opportunities and higher fitness for similar species. Additionally, traits that could be affected by pressures in one area, such as a city, could be different than traits that are threatened by pressures in forests such as from logging.

We combined the IUCN's Redlist status of birds and mammals with the Elton Traits database, and used traits of birds and mammals to predict status. We used classification models, to predict whether species is least concern, near threatened, vulnerable, or endangered, where we lumped endangered, highly endangered, extinct in wild, and extinct into one category. These were combined, because between when the Elton Traits were published in 2014 and 2020 when the IUCN Redlist were updated, some species went extinct, so there were low numbers in each of those categories and lumping helped make the models more generalizable.

After determining the best model that predicts status, we used the model to predicted the IUCN Redlist Status for the species where the status is unknown.



# Data Cleaning



```{r loading packages}

library(tidyverse)
library(Hmisc)

```

```{r set pathways, eval=FALSE}

## Local Pathways - copy/paste your local pathway to the github repository

# Emma
pathway = "/Users/emmabarton/Desktop/spring_2020/STAT434/project/"

# Ryan
#pathway = "~/GitHub/"

```

## Loading Datasets

```{r raw data, eval=FALSE}

redlist_df = read.csv(paste0(pathway, "STAT-434---not-the-dodo-/simple_summary_IUCN_birds_mammals.csv"))

elton_mammal_df = read.csv(paste0(pathway, "STAT-434---not-the-dodo-/EltonTraits/MamFuncDat.txt"),sep = "\t")

elton_bird_df = read.csv(paste0(pathway, "STAT-434---not-the-dodo-/EltonTraits/BirdFuncDat.txt"),sep = "\t")

```

```{r change raw data types, eval=FALSE}

redlist_df$scientificName = as.character(redlist_df$scientificName)
elton_mammal_df$scientificName = as.character(elton_mammal_df$Scientific)
elton_bird_df$scientificName = as.character(elton_bird_df$Scientific)

```

```{r join elton and redlist, eval=FALSE}

# Filter mammals and birds from redlist species
redlist_mammals_df = redlist_df[redlist_df$className=="MAMMALIA",]
redlist_birds_df = redlist_df[redlist_df$className=="AVES",]

# Join Elton traits and redlist species for mammals
mammal_df = left_join(x = elton_mammal_df, y = redlist_mammals_df, 
                      by="scientificName")

# Join Elton traits and redlist species for birds
bird_df = left_join(x = elton_bird_df, y = redlist_birds_df,  
                    by="scientificName")

# Write data
write.csv(mammal_df, "uncleaned_mammal_df.csv")
write.csv(bird_df, "uncleaned_bird_df.csv")

```

```{r uncleaned data, eval=FALSE}

mammal_df = read.csv("uncleaned_mammal_df.csv")
bird_df = read.csv("uncleaned_bird_df.csv")

```

## Data Cleaning

```{r data dimensions, eval=FALSE}

dim(mammal_df)
dim(bird_df)

```

```{r missing redlist species, eval=FALSE}

table(is.na(mammal_df$Diet.Vect))
nrow(mammal_df)
nrow(elton_mammal_df)
nrow(redlist_mammals_df)

# Check redlist mammals that do not have Elton traits
redlist_mammals_df %>% 
  filter(!(scientificName %in% elton_mammal_df$scientificName)) %>% 
  nrow()

# Check redlist birds that do not have Elton traits
redlist_birds_df %>% 
  filter(!(scientificName %in% elton_bird_df$scientificName)) %>% 
  nrow()

```

```{r select columns, eval=FALSE}

# Removed unnecessary or mostly empty columns
mammal_df = mammal_df %>% 
  select(-X, -MSW3_ID, -infraType, -infraName, -infraAuthority, 
         -redlistCriteria, -criteriaVersion)

bird_df = bird_df %>% 
  select(-X, -infraType, -infraName, -infraAuthority, 
         -redlistCriteria, -criteriaVersion)

```

```{r missing redlist status, eval=FALSE}

mammal_df %>% 
  filter(is.na(redlistCategory)) %>% 
  nrow()

bird_df %>% 
  filter(is.na(redlistCategory)) %>% 
  nrow()

```

```{r filter out missing redlist status, eval=FALSE}

# Create prediction/test datasets 
mammal_pred_df = mammal_df %>% 
  filter(is.na(redlistCategory))

bird_pred_df = bird_df %>% 
  filter(is.na(redlistCategory))

# Filter out rows with missing redlist category to make training dataset
mammal_df = mammal_df %>% 
  filter(!is.na(redlistCategory))

bird_df = bird_df %>% 
  filter(!is.na(redlistCategory))

```

```{r change factor levels, eval=FALSE}

mammal_df = mammal_df %>% 
  mutate(
    populationTrend = case_when(
      populationTrend == "" ~ "Unknown",
      TRUE ~ as.character(populationTrend)
    )
  )

```

```{r write cleaned data, eval=FALSE}

write.csv(mammal_df, "cleaned_mammal_df.csv")
write.csv(bird_df, "cleaned_bird_df.csv")

write.csv(mammal_pred_df, "mammal_pred_df.csv")
write.csv(bird_pred_df, "bird_pred_df.csv")

```

Not having much luck matching these 500 mammal taxons. maybe just drop them??
```{r matching extra mammal species, eval=FALSE}

# matching MAMMAL species that didnt have a perfect match between the IUCN and EltonTraits databases
mammal_pred_df = read.csv("mammal_pred_df.csv")

syn_df = read.csv("asm-species-2020-05-27_containssynonymsfromeltontraits.csv")

#removing the empty columns from the missing IUCN join
mammal_pred_df = mammal_pred_df[,1:27]

#reformatting the deprecated.scientific name column from: {"herpestes javanica":":$2009"}

#chopping off the first two characters

syn_df$Deprecated.Scientific = gsub('^."([^"]*[^"]*)".*$', "\\1",syn_df$Deprecated.Scientific)

#capitalizing
syn_df$Deprecated.Scientific = capitalize(syn_df$Deprecated.Scientific)

mammal_pred_df %>% 
  filter(!(scientificName %in% syn_df$Deprecated.Scientific)) %>% 
  unique()

mammal_pred_df$scientificName = as.character(mammal_pred_df$scientificName)
syn_df$Deprecated.Scientific = as.character(syn_df$Deprecated.Scientific)
syn_df$Canonical.Sciname = as.character(syn_df$Canonical.Sciname)

for (i in 1:nrow(mammal_pred_df)){
  sci_index = match(mammal_pred_df$scientificName[i],syn_df$Deprecated.Scientific)
  if (is.na(sci_index)==FALSE) {
    mammal_pred_df$scientificName[i] = syn_df$Canonical.Sciname[sci_index]
  }else {
    mammal_pred_df$scientificName[i] = NA
  }
}

```

TaxonomicChanges_BirdLife_Avibase.csv was scrapped from avibase.bs-eoc.org
https://avibase.bsc-eoc.org/compare.jsp?source1=birdlife&version1=BIRDLIFE03&source2=birdlife&version2=BIRDLIFE12&continent=&reg_type=9

It is a table with that matches the Birdlife checklist version 3 (EltonTraits uses) with the HBW Birdlife Taxonomic Checklist v4 (which IUCN uses). Using this table to change names to the new taxonomic system to change the taxonomic system used in EltonTraits to the more updated v4. 

http://datazone.birdlife.org/species/taxonomy
^birdlife taxonomy


 	
```{r matching extra bird species, eval=FALSE}

# matching BIRDS that didnt have a perfect match between the IUCN and EltonTraits databases
mammal_pred_df = read.csv("mammal_pred_df.csv")

bird_pred_df = read.csv("bird_pred_df.csv")

avibase_df = read.csv("TaxonomicChanges_Birdlife_Avibase.csv")
avibase_df = avibase_df[,2:ncol(avibase_df)] #chopping off the 
avibase_ioc_df = read.csv("TaxonomicChanges_IOC27_HBWBirdlife4.csv")
avibase_ioc_df$Scientific.name = avibase_ioc_df$'Ã¯..Scientific.name'

#matching taxonomy from Birdlife v3 to HBW v4, filtering out ones that don't match (the ones using taxonomy IOC 2.7 don't match)
bird_pred_df %>% 
  filter((!scientificName %in% avibase_df$Scientific.name)) %>% 
  unique()

#looking at taxons that don't match within IOC2.7 or birdlife v3
bird_pred_df %>% 
  filter((!scientificName %in% avibase_df$Scientific.name)) %>% 
  filter((!scientificName %in% avibase_ioc_df$Scientific.name)) %>%
  unique()

#changing to character to avoid errors
bird_pred_df$scientificName = as.character(bird_pred_df$scientificName)
avibase_df$Scientific.name = as.character(avibase_df$Scientific.name)
avibase_df$Scientific.name2 = as.character(avibase_df$Scientific.name2)
avibase_ioc_df$Scientific.name = as.character(avibase_ioc_df$Scientific.name)
avibase_ioc_df$Scientific.name2 = as.character(avibase_ioc_df$Scientific.name2)

#loop through and update name to correct taxon
for(i in 1:nrow(bird_pred_df)) {
  sci_index = match(bird_pred_df$scientificName[i],avibase_df$Scientific.name,nomatch=0)
  if(sci_index==0){ # then is in IOC2.7 database
    sci_index = match(bird_pred_df$scientificName[i],avibase_ioc_df$Scientific.name,nomatch=0)
    if(sci_index!=0){ #if it matches, then we assign it to the correct taxonomy
      bird_pred_df$scientificName[i] = avibase_ioc_df$Scientific.name2[sci_index]
    }else{
      bird_pred_df$scientificName[i] = NA
    }
    
  }else{ # then is in the birdlife 3 database and assign it to the correct taxonomy
    bird_pred_df$scientificName[i] = avibase_df$Scientific.name2[sci_index]
  }
}

#saving those with missing taxonomy to a datafile
bird_pred_df %>%
  filter(scientificName == "") %>%
  write.csv("missingtaxonomy_birds.csv")

#removing those taxons with missing taxonomy
bird_pred_df2 = bird_pred_df %>%
  filter(scientificName != "")

#chopping off some columns
bird_pred_df2 = bird_pred_df2[,1:42]

redlist_birds_df$scientificName = as.character(redlist_birds_df$scientificName)

new_bird_df = left_join(x = bird_pred_df2, y = redlist_birds_df,  
                    by="scientificName")

clean_bird_df = read.csv("cleaned_bird_df.csv")

colnames(clean_bird_df)
colnames(new_bird_df)

new_bird_df = new_bird_df %>% 
  dplyr::select(-infraType, -infraName, -infraAuthority, 
         -redlistCriteria, -criteriaVersion)

new_clean_bird_df = rbind(clean_bird_df,new_bird_df)

write.csv(new_clean_bird_df,"cleaned_bird_df_updated_5_29.csv")

```

# Data Exploration






## Set Up

```{r load packages}

library(tidyverse)

```

```{r set pathway}

## Local Pathways - copy/paste your local pathway to the github repository

# Emma
pathway = "/Users/emmabarton/Desktop/spring_2020/STAT434/project/"

# Ryan
#pathway = "~/GitHub/STAT-434---not-the-dodo-/"

```

```{r load data}

mammal_df = read.csv("cleaned_mammal_df.csv")
bird_df = read.csv("cleaned_bird_df_updated_5_29.csv")

```

## Data Exploration

Elton traits: diet, foraging strata, foraging time, and body size. 

## Mammals

```{r mammal variables}

names(mammal_df)

```
Diet variables are the estimated percent use of Inv: invertebrates Vend: mammals and birds, Vect: reptiles, snakes, amphibians, salamanders, Vfish: fish, Vunk: general vertebrates or unknown, Scav: scavenge, garbage, offal, carcasses, trawlers, carrion, Fruit: fruit and drupes, Nect: nector, pollen, plant exudates, gums, Seed: seed, maize, nuts, spores, wheat, grains, Plant: other plant material. All diet categories should add to 100%.

Diet source is a reference ID and diet certainty is the estimated reliability of the diet sources (see metadata for rankings).

ForStrat.Value: One of five foraging stratum categories (marine, ground, scansorial, arboreal, aerial).

Activity variables are binary 0:no, 1:yes. Nocturnal: night, Crepuscular: twilight, Diurnal: day. 

Bodymass.Value: average adult body mass (g)

Redlist Category: Critically Endangered, Data Deficient, Endangered, Extinct, Extinct in the Wild, Least Concern, Near Threatened, Vulnerable

### Single Variable Distributions

```{r mammal single variable tables}

# Response: Redlist Category
table(mammal_df$redlistCategory)

# Body Mass distribution
mammal_df %>% 
  mutate(
    bodymass_bin = case_when(
      BodyMass.Value >= 100000 ~ ">=100,000",
      BodyMass.Value < 100000 & BodyMass.Value >= 10000 ~ "10,000 - 100,000",
      BodyMass.Value < 10000 & BodyMass.Value >= 1000 ~ "10,000 - 1,000",
      BodyMass.Value < 1000 & BodyMass.Value >= 100 ~ "1,000 - 100",
      BodyMass.Value < 100 ~ "<100"
     )
  ) %>% 
  group_by(bodymass_bin) %>% 
  dplyr::summarize(n = n())

```
The majority of species in our dataset are of least concern, followed by data deficient and vulnurable. However, combining critically endangered, endangered, extinct, and extinct in the wild results in 626 species.

The majority of mammals have a bodymass less than 100g followed by a bodymass between 1069. There are some mammals with a bodymass orders of magnitude greater than 100,000g. 

```{r mammal single variable graphs}

# Body Mass Histogram
ggplot(mammal_df, aes(BodyMass.Value)) + 
  geom_histogram(binwidth = 25000000) + 
  theme_classic()

# Log Transformed Body Mass Histogram
ggplot(mammal_df, aes(BodyMass.Value)) + 
  geom_histogram() + 
  scale_x_continuous(trans = "log") +
  theme_classic()

```
Because of the large disparity between large mammals with a much greater body mass than 100,000 and the majority of mammals, the distribution of bodymass is very skewed right. 

### Pairwise Relationships

```{r mammal explanatory vs response tables}

# Redlist Category vs Population Trend
table(mammal_df$redlistCategory, mammal_df$populationTrend)

# Redlist Category vs Foraging Stratum 
prop.table(table(mammal_df$redlistCategory,mammal_df$ForStrat.Value),2)*100 #makes a nice looking table with % by column

```

```{r mammal explanatory vs response graphs}

# 1
# Population Trend and Redlist Category Bar Plot
mammal_df %>% 
  mutate(
    redlistCat2 = case_when(
      redlistCategory == "Critically Endangered" ~ "Endangered or Extinct",
      redlistCategory == "Endangered" ~ "Endangered or Extinct",
      redlistCategory == "Extinct" ~ "Endangered or Extinct",
      redlistCategory == "Extinct in the Wild" ~ "Endangered or Extinct",
      TRUE ~ as.character(redlistCategory)
    )
  ) %>% 
  ggplot(aes(populationTrend)) +
    geom_bar(col = "black") +
    facet_wrap(~redlistCat2) +
    coord_flip() +
    theme_classic()

# 2
# Redlist Category vs Body Mass Value Box Plot
mammal_df %>% 
  mutate(
    redlistCat2 = case_when(
      redlistCategory == "Critically Endangered" ~ "Endangered or Extinct",
      redlistCategory == "Endangered" ~ "Endangered or Extinct",
      redlistCategory == "Extinct" ~ "Endangered or Extinct",
      redlistCategory == "Extinct in the Wild" ~ "Endangered or Extinct",
      TRUE ~ as.character(redlistCategory)
    )
  ) %>% 
  ggplot(aes(redlistCat2, BodyMass.Value)) +
    geom_boxplot() +
    coord_flip() +
    scale_y_continuous(trans = "log") +
    theme_classic()

# 3 
# Average Diet Percent Use vs Redlist Category Barplots
mammal_df %>% 
  mutate(
    redlistCat2 = case_when(
      redlistCategory == "Critically Endangered" ~ "Endangered or Extinct",
      redlistCategory == "Endangered" ~ "Endangered or Extinct",
      redlistCategory == "Extinct" ~ "Endangered or Extinct",
      redlistCategory == "Extinct in the Wild" ~ "Endangered or Extinct",
      TRUE ~ as.character(redlistCategory)
    )
  ) %>% 
  gather(key = "diet_type", value = "percentage", Diet.Inv, Diet.Vend, 
         Diet.Vect, Diet.Vfish, Diet.Vunk, Diet.Scav, Diet.Fruit, Diet.Nect,
         Diet.Seed, Diet.PlantO) %>% 
  ggplot(aes(diet_type, percentage)) +
    stat_summary(geom = "bar", fun = mean, position = position_dodge(), 
                 colour = "black", fill = "white",
                 width = 0.7) +
    stat_summary(geom = "errorbar", fun.data = mean_se, 
                 position = position_dodge(0.7),
                 width = 0.25) +
    facet_wrap(~redlistCat2) +
    coord_flip() +
    theme_classic()

# 4
# Foraging Stratum and Redlist Category Bar Plot
mammal_df %>% 
  mutate(
    redlistCat2 = case_when(
      redlistCategory == "Critically Endangered" ~ "Endangered or Extinct",
      redlistCategory == "Endangered" ~ "Endangered or Extinct",
      redlistCategory == "Extinct" ~ "Endangered or Extinct",
      redlistCategory == "Extinct in the Wild" ~ "Endangered or Extinct",
      TRUE ~ as.character(redlistCategory)
    )
  ) %>% 
  ggplot(aes(ForStrat.Value)) +
    geom_bar(col = "black") +
    facet_wrap(~redlistCat2) +
    theme_classic()

```
1) The majority of endangered or extinct mammals (critically endangered, endangered, extinct, and extinct in the wild grouped into one category) have a decreasing population trend. The majority of vulnerable and near threatened mammals also have a decreasing population trend. The majority of least concern mammals have either a stable population trend or an unknown population trend. 

It is very likely that the redlist category of a mammal is designated based on population trend knowledge. Many of the mammals in the least concern category may actually be more threatened than believed becasue their population trend is unknown.  

2) Natural log transformed body mass value (g) vs redlist category. There are visually no major differences in body mass distributions between categories other than mammals categorized as least concern and data deficient seem to have more outliers with large body mass values. 

3) Average percent use of each diet category for each redlist category. Averages appear similar across redlist categories. 

4) Distribution of foraging stratum divided by redlist category. Mammals that are of least concern have a higher proportion of ground foragers. Other than this there are appear to be no major differences between the categories.      

```{r mammal explanatory vs explanatory graphs}

# 5
# Average Percent Use of Each Diet Type
mammal_df %>% 
  gather(key = "diet_type", value = "percentage", Diet.Inv, Diet.Vend, 
         Diet.Vect, Diet.Vfish, Diet.Vunk, Diet.Scav, Diet.Fruit, Diet.Nect,
         Diet.Seed, Diet.PlantO) %>% 
  ggplot(aes(diet_type, percentage)) + 
    stat_summary(geom = "bar", fun = mean, position = position_dodge(), 
                 colour = "black", fill = "white",
                 width = 0.7) +
    stat_summary(geom = "errorbar", fun.data = mean_se, 
                 position = position_dodge(0.7),
                 width = 0.25) +
    coord_flip() + 
    theme_classic()

# 6 
# Activity vs Body Mass Boxplot
mammal_df %>%
  gather(key = "activity_type", value = "value", Activity.Nocturnal, 
         Activity.Crepuscular, Activity.Diurnal) %>% 
  filter(value == 1) %>% 
  ggplot(aes(activity_type, BodyMass.Value)) +
    geom_boxplot() +
    scale_y_continuous(trans = "log") +
    coord_flip() +
    theme_classic()

```
5) Invertebrates were the diet component with the highest average percent use, followed by other plant parts and fruit.

6) Average body mass value for each activity type. Diurnal and Crepuscular have slightly larger median bodymass values. 

## Birds 

```{r variables}

names(bird_df)

```
Diet variables are the estimated percent use of Inv: invertebrates Vend: mammals and birds, Vect: reptiles, snakes, amphibians, salamanders, Vfish: fish, Vunk: general vertebrates or unknown, Scav: scavenge, garbage, offal, carcasses, trawlers, carrion, Fruit: fruit and drupes, Nect: nector, pollen, plant exudates, gums, Seed: seed, maize, nuts, spores, wheat, grains, Plant: other plant material. All diet categories should add to 100%.

Diet.5Cat: assignment to one of five diet categories (PlantSeed, FruiNect, Invertebrate, VertFishScav, Omnivore)

Foraging stratum variables are the estimated percent use of watbelowsurf: below water surface, wataroundsurf: on water surface, ground: ground, understory: below 2m in understory, midhigh: higher than 2m but below canopy, canopy: canopy, aerial: well above tree structures. All foraging stratum categories should add to 100%. 

PelagicSpecialist: binary variable for foraging being mostly pelagic.

Nocturnal: binary variable for night foraging

Bodymass.Value: average adult body mass (g)

Redlist Category: Critically Endangered, Data Deficient, Endangered, Extinct, Extinct in the Wild, Least Concern, Near Threatened, Vulnerable


### Single Variable Distributions

```{r bird single variable tables}

# Response: Redlist Category
table(bird_df$redlistCategory)

# Body Mass distribution
bird_df %>% 
  mutate(
    bodymass_bin = case_when(
      BodyMass.Value >= 100000 ~ ">=100,000",
      BodyMass.Value < 100000 & BodyMass.Value >= 10000 ~ "10,000 - 100,000",
      BodyMass.Value < 10000 & BodyMass.Value >= 1000 ~ "10,000 - 1,000",
      BodyMass.Value < 1000 & BodyMass.Value >= 100 ~ "1,000 - 100",
      BodyMass.Value < 100 ~ "<100"
     )
  ) %>% 
  group_by(bodymass_bin) %>% 
  dplyr::summarize(n = n())

```
The majority of species in our dataset are of least concern, followed by data deficient and vulnurable. However, combining critically endangered, endangered, extinct, and extinct in the wild results in 592 species.

The majority of birds have a bodymass less than 100g followed by a bodymass between 1000 and 100 grams There afre very view with greater than 10,000 grams. 

```{r bird single variable graphs}

# Body Mass Histogram
ggplot(bird_df, aes(BodyMass.Value)) + 
  geom_histogram(binwidth = 25000000) + 
  theme_classic()

# Log Transformed Body Mass Histogram
ggplot(bird_df, aes(BodyMass.Value)) + 
  geom_histogram() + 
  scale_x_continuous(trans = "log") +
  theme_classic()

```
Because of the large disparity between large birds, such as ostriches and emus, with a much greater body mass than most birds, the distribution of bodymass is skewed right. 

### Pairwise Relationships


```{r bird explanatory vs response graphs}

# 1
# Population Trend and Redlist Category Bar Plot
bird_df %>% 
  mutate(
    redlistCat2 = case_when(
      redlistCategory == "Critically Endangered" ~ "Endangered or Extinct",
      redlistCategory == "Endangered" ~ "Endangered or Extinct",
      redlistCategory == "Extinct" ~ "Endangered or Extinct",
      redlistCategory == "Extinct in the Wild" ~ "Endangered or Extinct",
      TRUE ~ as.character(redlistCategory)
    )
  ) %>% 
  ggplot(aes(populationTrend)) +
    geom_bar(col = "black") +
    facet_wrap(~redlistCat2) +
    coord_flip() +
    theme_classic()

# 2
# Redlist Category vs Body Mass Value Box Plot
bird_df %>% 
  mutate(
    redlistCat2 = case_when(
      redlistCategory == "Critically Endangered" ~ "Endangered or Extinct",
      redlistCategory == "Endangered" ~ "Endangered or Extinct",
      redlistCategory == "Extinct" ~ "Endangered or Extinct",
      redlistCategory == "Extinct in the Wild" ~ "Endangered or Extinct",
      TRUE ~ as.character(redlistCategory)
    )
  ) %>% 
  ggplot(aes(redlistCat2, BodyMass.Value)) +
    geom_boxplot() +
    coord_flip() +
    scale_y_continuous(trans = "log") +
    theme_classic()

# 3 
# Average Diet Percent Use vs Redlist Category Barplots
bird_df %>% 
  mutate(
    redlistCat2 = case_when(
      redlistCategory == "Critically Endangered" ~ "Endangered or Extinct",
      redlistCategory == "Endangered" ~ "Endangered or Extinct",
      redlistCategory == "Extinct" ~ "Endangered or Extinct",
      redlistCategory == "Extinct in the Wild" ~ "Endangered or Extinct",
      TRUE ~ as.character(redlistCategory)
    )
  ) %>% 
  gather(key = "diet_type", value = "percentage",Diet.Inv, Diet.Vend, 
         Diet.Vect, Diet.Vfish, Diet.Vunk, Diet.Scav, Diet.Fruit, Diet.Nect,
         Diet.Seed, Diet.PlantO) %>% 
  ggplot(aes(diet_type, percentage)) +
    stat_summary(geom = "bar", fun = mean, position = position_dodge(), 
                 colour = "black", fill = "white",
                 width = 0.7) +
    stat_summary(geom = "errorbar", fun.data = mean_se, 
                 position = position_dodge(0.7),
                 width = 0.25) +
    facet_wrap(~redlistCat2) +
    coord_flip() +
    theme_classic()

# 4
# Foraging Stratum and Redlist Category Bar Plot
bird_df %>% 
  mutate(
    redlistCat2 = case_when(
      redlistCategory == "Critically Endangered" ~ "Endangered or Extinct",
      redlistCategory == "Endangered" ~ "Endangered or Extinct",
      redlistCategory == "Extinct" ~ "Endangered or Extinct",
      redlistCategory == "Extinct in the Wild" ~ "Endangered or Extinct",
      TRUE ~ as.character(redlistCategory)
    )
  ) %>% 
  gather(key = "foraging_type", value = "percentage","ForStrat.watbelowsurf" , "ForStrat.wataroundsurf" ,"ForStrat.ground",       
 "ForStrat.understory" ,   "ForStrat.midhigh"   ,    "ForStrat.canopy"    ,    "ForStrat.aerial"     ,  
  "PelagicSpecialist" ) %>% 
  ggplot(aes(foraging_type, percentage)) +
    stat_summary(geom = "bar", fun = mean, position = position_dodge(), 
                 colour = "black", fill = "white",
                 width = 0.7) +
    stat_summary(geom = "errorbar", fun.data = mean_se, 
                 position = position_dodge(0.7),
                 width = 0.25) +
    facet_wrap(~redlistCat2) +
    coord_flip() +
    theme_classic()




```
1) The majority of endangered or extinct birds (critically endangered, endangered, extinct, and extinct in the wild grouped into one category) have a decreasing population trend. The majority of vulnerable and near threatened birds also have a decreasing population trend. The majority of least concern birds have either a stable population trend or a decreasing population trend. 

It is very likely that the redlist category of a bird is designated based on population trend knowledge. Many of the birds in the least concern category may actually be more threatened than believed becasue their population trend is unknown. Thus, we will be excluding this variable from out models.

2) Natural log transformed body mass value (g) vs redlist category. On average, the endangered or extinct birds have higher body mass than least concern, and endangered and extinct and vulnerable have similar body mass.

3) Average percent use of each diet category for each redlist category. Averages appear pretty similar across redlist categories, but least concern species tend to have higher percentages of invertebrates in their diet than other cateogires most scavenging birds have higher status (endangered being considered a higher status than vulnerable than near threatened and finally least concern). 

4) Distribution of foraging strageties divided by redlist category. There appears to be a some variation. For instance, aerial foraging birds tend to be lower status.       

```{r bird explanatory vs explanatory graphs}

# 5
# Average Percent Use of Each Diet Type
bird_df %>% 
  gather(key = "diet_type", value = "percentage", Diet.Inv, Diet.Vend, 
         Diet.Vect, Diet.Vfish, Diet.Vunk, Diet.Scav, Diet.Fruit, Diet.Nect,
         Diet.Seed, Diet.PlantO) %>% 
  ggplot(aes(diet_type, percentage)) + 
    stat_summary(geom = "bar", fun = mean, position = position_dodge(), 
                 colour = "black", fill = "white",
                 width = 0.7) +
    stat_summary(geom = "errorbar", fun.data = mean_se, 
                 position = position_dodge(0.7),
                 width = 0.25) +
    coord_flip() + 
    theme_classic()


```
5) Invertebrates were the diet component with the highest average percent use, followed by other plant parts and fruit.


```{r investigate birds}

prop.table(table(bird_df$redlistCategory))*100

prop.table(table(bird_df$redlistCategory,bird_df$populationTrend),2)*100

prop.table(table(bird_df$redlistCategory,bird_df$Diet.Inv),2)*100

prop.table(table(bird_df$redlistCategory,bird_df$Diet.Nect),2)*100

prop.table(table(bird_df$redlistCategory,bird_df$Nocturnal),2)*100

prop.table(table(bird_df$redlistCategory,bird_df$PelagicSpecialist),2)*100

#Deciding which ones to include based on whether different redlistcategories have different percentages in each percentage of variable 

prop.table(table(bird_df$redlistCategory,bird_df$ForStrat.watbelowsurf),2)*100 #include in model

prop.table(table(bird_df$redlistCategory,bird_df$ForStrat.wataroundsurf),2)*100 # include in model
 
prop.table(table(bird_df$redlistCategory,bird_df$ForStrat.ground),2)*100 #even across all categories so not including in model

prop.table(table(bird_df$redlistCategory,bird_df$ForStrat.understory),2)*100 #pretty even across categories, not including

prop.table(table(bird_df$redlistCategory,bird_df$ForStrat.midhigh),2)*100 #pretty even across categories, not including

prop.table(table(bird_df$redlistCategory,bird_df$ForStrat.canopy),2)*100 # moderately even

prop.table(table(bird_df$redlistCategory,bird_df$ForStrat.aerial),2)*100 #very high proportion in least concern, including

sapply(split(bird_df$BodyMass.Value,bird_df$redlistCategory),mean)
sapply(split(bird_df$BodyMass.Value,bird_df$redlistCategory),length)

```

# Modeling

Types of models to use:

Classification models only (could convert classes to numeric 1 thru 4, but makes our prediction undesirable, plus not equal jumps between classes)

  1. Logistic Regression (pairwise/one-versus-one and one-versus-all)?
  2. Linear Discriminant Analysis
  3. Quadratic Discriminant Analysis
  4. K-Nearest Neighbor
  5. Classification Tree
  6. Bagged Trees
  7. Random Forests
  8. Boosted Forests
  9. Neural Networks
  10. Support Vector Machines
  
Additional Considerations for Modeling

  1. PCA of all diet and foraging variables
    a. All diet variables are highly correlated, because they each sum up to 100. Thus, using PCA could really simplify the models considerably
    b. Additionally, if PCA is performed on diet variables then the diet variables should not be scaled because they already are by nature of the data
  
# Set Up

```{r}

library(tidyverse)
library(class)
library(tree)
library(randomForest)
library(MASS)
library(e1071)
library(nnet)
library(gbm)

```

```{r}

mammal_df = read.csv("cleaned_mammal_df.csv")
bird_df = read.csv("cleaned_bird_df_updated_5_29.csv")

```

```{r chopping off extra rows}

nrow(bird_df)
bird_df = bird_df[1:9640,]

```

# Preparing Data

## Transforming Variables

```{r changing variable types}

# Converting mammal activity variables to factors 
mammal_df$Activity.Nocturnal = as.factor(mammal_df$Activity.Nocturnal)
mammal_df$Activity.Crepuscular = as.factor(mammal_df$Activity.Crepuscular)
mammal_df$Activity.Diurnal = as.factor(mammal_df$Activity.Diurnal)
mammal_df$redlistCategory = as.factor(mammal_df$redlistCategory)

# Converting bird activity variables to factors 
bird_df$Nocturnal = as.factor(bird_df$Nocturnal)
bird_df$redlistCategory = as.factor(bird_df$redlistCategory)

```

```{r response variable transformations}

# Combine "Extinct" & "Extinct in the Wild" & "Critically Endangered" into "Endangered"
mammal_df$redlistCategory = as.character(car::recode(mammal_df$redlistCategory,recodes = "'Extinct'='Endangered';'Extinct in the Wild'='Endangered';'Critically Endangered'='Endangered'"))

bird_df$redlistCategory = as.character(car::recode(bird_df$redlistCategory,recodes = "'Extinct'='Endangered';'Extinct in the Wild'='Endangered';'Critically Endangered'='Endangered'"))

```

```{r explanatory variable transformations}

# Mammal Explanatory Variable Transformations
mammal_df = mammal_df %>% 
  mutate(
    log_bodymass = log(BodyMass.Value)
  )


# Bird Explanatory Variable Transformations 

bird_df = bird_df %>% 
  mutate(
    log_bodymass = log(BodyMass.Value)
  )
```

## Adding PCA of Diet and Foraging

Creating data frames with Principle Components as columns
```{r}

pcbirddiet = prcomp(bird_df[,c(12:21)],scale=FALSE)

pcbirdforage = prcomp(bird_df[,c(26:32)],scale=FALSE)

pcmammal = prcomp(mammal_df[,c(4:13)],scale = FALSE)

pcbird = prcomp(bird_df[,c(12:21,26:32)],scale=FALSE)

summary(pcmammal)


plot(cumsum(pcbirddiet$sdev^2/sum(pcbirddiet$sdev^2)), xlab="Principal  Component", ylab="Cumulative  Proportion  of Variance  Explained", ylim=c(0,1),type="b",main = "Bird Diet")

plot(cumsum(pcmammal$sdev^2/sum(pcmammal$sdev^2)), xlab="Principal  Component", ylab="Cumulative  Proportion  of Variance  Explained", ylim=c(0,1),type="b",main = "Mammal Diet")


plot(cumsum(pcbirdforage$sdev^2/sum(pcbirdforage$sdev^2)), xlab="Principal  Component", ylab="Cumulative  Proportion  of Variance  Explained", ylim=c(0,1),type="b",main = "Bird Foraging")

plot(cumsum(pcbird$sdev^2/sum(pcbird$sdev^2)), xlab="Principal  Component", ylab="Cumulative  Proportion  of Variance  Explained", ylim=c(0,1),type="b",main = "Bird Foraging and Diet")


colnames(pcbirddiet$x) = paste("Diet",colnames(pcbirddiet$x),sep = "")

colnames(pcmammal$x) = paste("Diet",colnames(pcmammal$x),sep = "")

colnames(pcbirdforage$x) = paste("For",colnames(pcbirdforage$x),sep = "")

colnames(pcbird$x) = paste("DietFor",colnames(pcbird$x),sep = "")

bird_df = cbind(bird_df,
                   cbind(pcbirddiet$x,
                         cbind(pcbirdforage$x,pcbird$x)))

mammal_df = cbind(mammal_df,pcmammal$x)

remove(pcbird,pcbirddiet,pcbirdforage,pcmammal)

```

## Making Training and Test Datasets

```{r separating data deficient observations}

# Moving data deficient mammals to different data set
data_deficient_mammals_df = mammal_df[mammal_df$redlistCategory == "Data Deficient",]
# Removing data deficient mammals
mammal_df = mammal_df[mammal_df$redlistCategory != "Data Deficient",]

# Moving data def birds to different dataset
data_deficient_birds_df = bird_df[bird_df$redlistCategory == "Data Deficient",]
# Removing data deficient birds
bird_df = bird_df[bird_df$redlistCategory != "Data Deficient",]

```

```{r creating test and training datasets}

# Creating indices for training sets
set.seed(10)
train_mammal = sample(1:nrow(mammal_df), size = round(nrow(mammal_df)/2))
train_bird = sample(1:nrow(bird_df), size = round(nrow(bird_df)/2))

# Creating training and test sets
mammal_train_df = mammal_df[train_mammal,]
mammal_test_df = mammal_df[-train_mammal,]

bird_train_df = bird_df[train_bird,]
bird_test_df = bird_df[-train_bird,]

```

# 1: Logistic Regression
  
## Mammal Logistic Regression

### Format Variables

```{r}

# Create separate logistic regression dataframe
mammals_log_train_df = mammal_train_df
mammals_log_test_df = mammal_test_df

# Change Response to Binary
mammals_log_train_df = mammals_log_train_df %>% 
  mutate(
    redlistCategory = case_when(
      redlistCategory == "Endangered" ~ 1,
      redlistCategory == "Near Threatened" ~ 1,
      redlistCategory == "Vulnerable" ~ 1,
      TRUE ~ 0
    )
  )

mammals_log_test_df = mammals_log_test_df %>% 
  mutate(
    redlistCategory = case_when(
      redlistCategory == "Endangered" ~ 1,
      redlistCategory == "Near Threatened" ~ 1,
      redlistCategory == "Vulnerable" ~ 1,
      TRUE ~ 0
    )
  )

```

### Variable Selection

```{r}

mammal_log_variables = list(c(38,4, 5, 6, 7, 8, 9, 10, 11, 12, 13), #all diet variables
                            c(38,7, 9, 10, 11, 12, 13),                  #selected diet variables
                            c(38,41),                               #log body mass
                            c(38,19, 20, 21, 41),                   #activity and body mass
                            c(38,4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 20, 21), #all diet and activity variables
                            c(38,4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 41),         #all diet and body mass
                            c(38,41, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 20, 21), #all diet and activity and body mass
                            c(38,7, 9, 10, 11, 12, 13, 41), #selected activity variables and body mass
                            c(38,7, 9, 10, 11, 12, 13, 19, 20, 21), #selected diet and activity
                            c(38,7, 9, 10, 11, 12, 13, 19, 20, 21, 41), #selected diet, activity and body mass
                            c(38,42, 43, 44, 45, 46, 47, 48), # 7 PC for diet
                            c(38,42, 43, 44, 45, 46, 47, 48, 41), # PCA for diet and diet
                            c(38,42, 43, 44, 45, 46, 47, 48, 19, 20, 21), # PCA for diet and activity
                            c(38,42, 43, 44, 45, 46, 47, 48, 19, 20, 21, 41), # PCA for diet, activity, and body mass
                            c(38,7, 9, 10, 11, 12, 13, 16),     #selected diet variables and foraging
                            c(38,7, 9, 10, 11, 12, 13, 41, 16), #selected activity variables and body mass and foraging
                            c(38, 16, 19, 20, 21), # activity and foraging
                            c(38, 16, 42, 43, 44, 45, 46, 47, 48, 41),   # PCA for diet, and body mass and foraging
                            c(38, 16, 42, 43, 44, 45, 46, 47, 48, 19, 20, 21, 41), #PCAdiet, and activity, body mass, and foraging
                            c(38,7, 9, 10, 11, 12, 13, 19, 20, 21, 41, 16)#selected diet, activity and body mass and foraging
                        
                            )  
test_errors = rep(0, length(mammal_log_variables))

for(i in 1:length(mammal_log_variables)){
  var = mammal_log_variables[[i]]
  mammal_log = glm(redlistCategory ~ .,
                   data = mammals_log_train_df[,var])
  log_prob = predict(mammal_log, newdata=mammals_log_test_df[,var], type = "response")
  log_pred = rep(0, 2146)
  log_pred[log_prob > 0.5] = 1
  test_errors[i] = mean(log_pred != mammals_log_test_df$redlistCategory)
}

which.min(test_errors)
mammal_log_variables[[which.min(test_errors)]]

# Best Variables: Selected diet variables, bodymass, and foraging

```

### Best Model

```{r}

var = mammal_log_variables[[16]]
mammal_log = glm(redlistCategory ~ .,
                   data = mammals_log_train_df[,var])
log_prob = predict(mammal_log, newdata=mammals_log_test_df[,var], type = "response")
log_pred = rep(0, 2146)
log_pred[log_prob > 0.5] = 1
mean(log_pred != mammals_log_test_df$redlistCategory)

# Error rate = 0.2795899

```

## Bird Logistic Regression
  
### Format Variables

```{r}

# Create separate logistic regression dataframe
bird_log_train_df = bird_train_df
bird_log_test_df = bird_test_df

# Change Response to Binary
bird_log_train_df = bird_log_train_df %>% 
  mutate(
    redlistCategory = case_when(
      redlistCategory == "Endangered" ~ 1,
      redlistCategory == "Near Threatened" ~ 1,
      redlistCategory == "Vulnerable" ~ 1,
      TRUE ~ 0
    )
  )

bird_log_test_df = bird_log_test_df %>% 
  mutate(
    redlistCategory = case_when(
      redlistCategory == "Endangered" ~ 1,
      redlistCategory == "Near Threatened" ~ 1,
      redlistCategory == "Vulnerable" ~ 1,
      TRUE ~ 0
    )
  )

```

### Variable Selection

```{r}
# Having trouble with bird logistic regression
bird_log_variables = list(#c(54, 12:21), # all diet variables
                          #c(54, 37,57), # activity and body mass
                          #c(54, 12:21, 37), # all diet and activity variables
                          #c(54, 12:21, 57), # all diet and body mass
                          #c(54, 12:21, 37, 57), # all diet and activity and body mass
                          c(54, 26:33), # foraging variables
                          #c(54, 26:33, 12:21), # diet and foraging
                          #c(54, 26:33, 57), # foraging and body mass
                          #c(54, 26:33, 12:21, 37, 57), 
                          # foraging, body mass, activity, and diet
                          #c(54, 75:91), # PCA for diet and foraing together
                          c(54, 75:91, 57), 
                          # PCA for diet and foraging together and body mass
                          c(54, 75:91, 57, 37)
                          # PCA for diet + foraging, activity, and body mass
                        )
test_errors = rep(0, length(bird_log_variables))

for(i in 1:length(bird_log_variables)){
  var = bird_log_variables[[i]]
  print(var)
  bird_log = glm(redlistCategory ~ .,
                   data = bird_log_train_df[,var])
  log_prob = predict(bird_log, newdata=bird_log_test_df[,var], type = "response")
  log_pred = rep(0, 2146)
  log_pred[log_prob > 0.5] = 1
  test_errors[i] = mean(log_pred != bird_log_test_df$redlistCategory)
}

which.min(test_errors)
#bird_log_variables[[which.min(test_errors)]]

```

# 2: Linear Discriminant Analysis

## Mammals

### Variable Selection

```{r}
mammal_lda_variables = list(c(38,7, 9, 10, 11, 12, 13),                  #selected diet variables
                            c(38,19, 20, 21, 41),                   #activity and body mass
                            c(38,41, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 20, 21), #all diet and activity and body mass
                            c(38,7, 9, 10, 11, 12, 13, 41), #selected activity variables and body mass
                            c(38,7, 9, 10, 11, 12, 13, 19, 20, 21), #selected diet and activity
                            c(38,7, 9, 10, 11, 12, 13, 19, 20, 21, 41), #selected diet, activity and body mass
                            c(38,42, 43, 44, 45, 46, 47, 48, 41), # PCA for diet and body mass
                            c(38,42, 43, 44, 45, 46, 47, 48, 19, 20, 21), # PCA for diet and activity
                            c(38,42, 43, 44, 45, 46, 47, 48, 19, 20, 21, 41), # PCA for diet, activity, and body mass
                            c(38,7, 9, 10, 11, 12, 13, 16),     #selected diet variables and foraging
                            c(38,7, 9, 10, 11, 12, 13, 41, 16), #selected activity variables and body mass and foraging
                            c(38, 16, 19, 20, 21), # activity and foraging
                            c(38, 16, 42, 43, 44, 45, 46, 47, 48, 41),   # PCA for diet, and body mass and foraging
                            c(38, 16, 42, 43, 44, 45, 46, 47, 48, 19, 20, 21, 41), #PCAdiet, and activity, body mass, and foraging
                            c(38,7, 9, 10, 11, 12, 13, 19, 20, 21, 41, 16)#selected diet, activity and body mass and foraging
                        
                            )  
test_errors = rep(0, length(mammal_lda_variables))

mammal_train_df[,mammal_lda_variables[[1]]]

for(i in 1:length(mammal_lda_variables)){
  var = mammal_lda_variables[[i]]
  mammal_lda = lda(redlistCategory ~ .,
                   data = mammal_train_df[,var])
  lda_pred = predict(mammal_lda,newdata=mammal_test_df[,var])
  test_errors[i] = mean(lda_pred$class != mammal_test_df$redlistCategory)
}

which.min(test_errors)
mammal_lda_variables[[which.min(test_errors)]]

```

### Best Model

```{r}

mammal_lda = lda(redlistCategory ~ .,
                   data = mammal_train_df[,mammal_lda_variables[[14]]])
lda_pred = predict(mammal_lda,newdata=mammal_test_df[,mammal_lda_variables[[14]]])
mean(lda_pred$class != mammal_test_df$redlistCategory)
table(pred=lda_pred$class,truth=mammal_test_df$redlistCategory)

#test error 0.3089469

colnames(mammal_train_df)[mammal_lda_variables[[14]]]
```

## Birds

```{r}

library(MASS)
library(pROC)

bird_lda1 = lda(redlistCategory ~ Diet.Inv + Diet.Vend + Diet.Vect + Diet.Vfish + Diet.Vunk + Diet.Scav + Diet.Fruit + Diet.Nect + Diet.Seed + Diet.PlantO + ForStrat.watbelowsurf + ForStrat.wataroundsurf + ForStrat.aerial +  PelagicSpecialist + Nocturnal + BodyMass.Value, data=bird_train_df)

bird_lda1_pred=predict(bird_lda1, bird_test_df)

table(preds = bird_lda1_pred$class, truth = bird_test_df$redlistCategory)

mean(bird_lda1_pred$class!=bird_test_df$redlistCategory)
#error rate 0.2315066


#Using first 11 PCs for Diet and Foraging PCs, because that is where the elbow is in the graph above
bird_lda_pca1 = lda(redlistCategory ~ DietForPC1 + DietForPC2 + DietForPC3 + DietForPC4 + DietForPC5 + DietForPC6 + DietForPC7 + DietForPC8 + DietForPC9 + DietForPC10 +DietForPC11 +  PelagicSpecialist + Nocturnal + scale(BodyMass.Value),data=bird_train_df)

bird_lda_pca1_pred=predict(bird_lda_pca1, bird_test_df)

table(preds = bird_lda_pca1_pred$class, truth = bird_test_df$redlistCategory)

mean(bird_lda_pca1_pred$class != bird_test_df$redlistCategory)
#error rate 0.2287977
colnames(bird_test_df)
```

### Variable Selection

```{r}

bird_lda_variables = list(c(54, 12:21), #all diet variables
                            c(54,57),                               #log body mass
                            c(54,37,57),                   #activity and body mass
                            c(54,12:21, 37), #all diet and activity variables
                            c(54,12:21, 57),         #all diet and body mass
                            c(54,12:21, 37, 57), #all diet and activity and body mass
                            c(54,26:33), # foraging variables
                            c(54,26:33, 12:21), # diet and foraging
                            c(54,26:33,57), #foraging and body mass
                            c(54,26:33, 12:21, 37, 57), # foraging, body mass, activity, and diet
                            c(54,75:85), # PCA for diet and foraing together
                            c(54,75:85, 57), # PCA for diet and foraging together and body mass
                            c(54,75:85, 57, 37) # PCA for diet + foraging, activity, and body mass
                            )
test_errors = rep(0, length(bird_lda_variables))



for(i in 1:length(bird_lda_variables)){
  var = bird_lda_variables[[i]]
  bird_lda = lda(redlistCategory ~ .,
                   data = bird_train_df[,var])
  lda_pred = predict(bird_lda,newdata=bird_test_df[,var])
  test_errors[i] = mean(lda_pred$class != bird_test_df$redlistCategory)
}

which.min(test_errors)
bird_lda_variables[[which.min(test_errors)]]
```

### Best Model

```{r}
bird_lda = lda(redlistCategory ~ .,
                   data = bird_train_df[,bird_lda_variables[[7]]])
lda_pred = predict(bird_lda,newdata=bird_test_df[,bird_lda_variables[[7]]])
mean(lda_pred$class != bird_test_df$redlistCategory)
table(pred=lda_pred$class,truth=bird_test_df$redlistCategory)

#test error 0.227339

colnames(bird_train_df)[mammal_lda_variables[[7]]]
```
Classifies all observations as least concern.

# 3: Quadratic Discriminant Analysis

## Mammals

### Variable Selection

```{r}

# using less variables to avoid rank deficiency, just removing some that have collinearity
mammal_qda_variables = list(c(38,4, 5, 6, 7, 8, 9, 10, 11,13), #all diet variables
                            c(38,7, 9, 10, 11, 13),                  #selected diet variables
                            c(38,41),                               #log body mass
                            c(38,19, 20, 21, 41),                   #activity and body mass
                            c(38,4, 5, 6, 7, 8, 9, 10, 11, 19, 20), #all diet and activity variables
                            c(38,4, 5, 6, 7, 8, 9, 10, 11, 13, 41),         #all diet and body mass
                            c(38,41, 4, 5, 6, 7, 8, 9, 10, 11, 13, 19, 20, 21), #all diet and activity and body mass
                            c(38,7, 9, 10, 11, 13, 41), #selected activity variables and body mass
                            c(38,7, 9, 10, 11, 13, 19, 20, 21), #selected diet and activity
                            c(38,7, 9, 10, 11, 13, 19, 20, 21, 41), #selected diet, activity and body mass
                            c(38,42, 43, 44, 45, 46, 47, 48), # 7 PC for diet
                            c(38,42, 43, 44, 45, 46, 47, 48, 41), # PCA for diet and diet
                            c(38,42, 43, 44, 45, 46, 47, 48, 19, 20, 21), # PCA for diet and activity
                            c(38,42, 43, 44, 45, 46, 47, 48, 19, 20, 21, 41), # PCA for diet, activity, and body mass
                            c(38,7, 9, 10, 11, 12, 13, 16),     #selected diet variables and foraging
                            c(38,7, 9, 10, 11, 12, 13, 41, 16), #selected activity variables and body mass and foraging
                            c(38, 16, 19, 20, 21), # activity and foraging
                            c(38, 16, 42, 43, 44, 45, 46, 47, 48, 41),   # PCA for diet, and body mass and foraging
                            c(38, 16, 42, 43, 44, 45, 46, 47, 48, 19, 20, 21, 41), #PCAdiet, and activity, body mass, and foraging
                            c(38,7, 9, 10, 11, 12, 13, 19, 20, 21, 41, 16)#selected diet, activity and body mass and foraging
                            )  
test_errors = rep(0, length(mammal_lda_variables))

for(i in 1:length(mammal_qda_variables)){
  var = mammal_qda_variables[[i]]
  mammal_qda = qda(redlistCategory ~ .,
                   data = mammal_train_df[,var])
  qda_pred = predict(mammal_qda,newdata=mammal_test_df[,var])
  test_errors[i] = mean(qda_pred$class != mammal_test_df$redlistCategory)
}

which.min(test_errors)
mammal_qda_variables[[which.min(test_errors)]]
```

### Best Model

```{r}
mammal_qda = qda(redlistCategory ~ .,
                   data = mammal_train_df[,mammal_qda_variables[[3]]])
qda_pred = predict(mammal_qda,newdata=mammal_test_df[,mammal_qda_variables[[3]]])
mean(qda_pred$class != mammal_test_df$redlistCategory)
table(pred=qda_pred$class,truth=mammal_test_df$redlistCategory)

#test error 0.3289842

colnames(mammal_train_df)[mammal_qda_variables[[3]]]
```

## Birds

### Variable Selection

```{r}
#removing first diet and foraging variables to avoid rank deficiency
bird_qda_variables = list(c(54, 13:21), #all diet variables
                            c(54,57),                               #log body mass
                            c(54,37,57),                   #activity and body mass
                            c(54,13:21, 37), #all diet and activity variables
                            c(54,13:21, 57),         #all diet and body mass
                            c(54,13:21, 37, 57), #all diet and activity and body mass
                            c(54,27:33), # foraging variables
                            c(54,27:33, 13:21), # diet and foraging
                            c(54,27:33,57), #foraging and body mass
                            c(54,27:33, 13:21, 37, 57), # foraging, body mass, activity, and diet
                            c(54,75:85), # PCA for diet and foraing together
                            c(54,75:85, 57), # PCA for diet and foraging together and body mass
                            c(54,75:85, 57, 37) # PCA for diet + foraging, activity, and body mass
                            )
test_errors = rep(0, length(bird_qda_variables))



for(i in 1:length(bird_qda_variables)){
  var = bird_qda_variables[[i]]
  bird_qda = qda(redlistCategory ~ .,
                   data = bird_train_df[,var])
  qda_pred = predict(bird_qda,newdata=bird_test_df[,var])
  test_errors[i] = mean(qda_pred$class != bird_test_df$redlistCategory)
}

which.min(test_errors)
bird_qda_variables[[which.min(test_errors)]]

```

### Best Model

```{r}
bird_qda = qda(redlistCategory ~ .,
                   data = bird_train_df[,bird_qda_variables[[2]]])
qda_pred = predict(bird_qda,newdata=bird_test_df[,bird_qda_variables[[2]]])
mean(qda_pred$class != bird_test_df$redlistCategory)
table(pred=qda_pred$class,truth=bird_test_df$redlistCategory)

#test error 0.2279642

colnames(bird_train_df)[bird_qda_variables[[2]]]
```

# 4: K-Nearest Neighbor

## Mammal K-Nearest Neighbor

### Format Variables
For some reason the knn function cannot deal with explanatory variables as factors so we'll have to recode categorical variables such as ForStrat.Value
```{r mammal change factors to numeric}

# Create separate dataframes for KNN
mammal_knn_train_df = mammal_train_df
mammal_knn_test_df = mammal_test_df

# Change factor variables to numeric
mammal_knn_train_df = mammal_knn_train_df %>% 
  mutate(
    Activity.Diurnal = as.numeric(Activity.Diurnal),
    Activity.Crepuscular = as.numeric(Activity.Crepuscular),
    Activity.Nocturnal = as.numeric(Activity.Nocturnal),
    
    for_strat_num = case_when(
      ForStrat.Value == "A" ~ 1,
      ForStrat.Value == "Ar" ~ 2,
      ForStrat.Value == "G" ~ 3,
      ForStrat.Value == "M" ~ 4,
      ForStrat.Value == "S" ~ 5
      ),
    for_strat_num = as.numeric(for_strat_num)
  )

mammal_knn_test_df = mammal_knn_test_df %>% 
  mutate(
    Activity.Diurnal = as.numeric(Activity.Diurnal),
    Activity.Crepuscular = as.numeric(Activity.Crepuscular),
    Activity.Nocturnal = as.numeric(Activity.Nocturnal),
    
    for_strat_num = case_when(
      ForStrat.Value == "A" ~ 1,
      ForStrat.Value == "Ar" ~ 2,
      ForStrat.Value == "G" ~ 3,
      ForStrat.Value == "M" ~ 4,
      ForStrat.Value == "S" ~ 5
      ),
    for_strat_num = as.numeric(for_strat_num)
  )

```

### Variable Selection
Explanatory Variables: Diet, Foraging Stratum, Activity, Body Mass. It appears that you cannot make single explanatory variable KNN models.
```{r mammal knn variable selection}

mammal_knn_variables = list(c(4, 5, 6, 7, 8, 9, 10, 11, 12, 13), # all diet variables
                            c(7, 9, 10, 11, 12, 13), # selected diet variables
                            c(19, 20, 21, 41), # activity and body mass
                            c(4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 20, 21), 
                            # all diet and activity variables
                            c(4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 41),        
                            # all diet and body mass
                            c(41, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 20, 21), 
                            # all diet and activity and body mass
                            c(7, 9, 10, 11, 12, 13, 41),
                            # selected activity variables and body mass
                            c(7, 9, 10, 11, 12, 13, 19, 20, 21), 
                            # selected diet and activity
                            c(7, 9, 10, 11, 12, 13, 19, 20, 21, 41), 
                            # selected diet, activity and body mass
                            c(42, 43, 44, 45, 46, 47, 48), # 7 PCA for diet
                            c(42, 43, 44, 45, 46, 47, 48, 41), 
                            # PCA for diet and bodymass
                            c(42, 43, 44, 45, 46, 47, 48, 19, 20, 21), 
                            # PCA for diet and activity
                            c(42, 43, 44, 45, 46, 47, 48, 19, 20, 21, 41), 
                            # PCA for diet, activity, and body mass
                            c(7, 9, 10, 11, 12, 13, 52),     
                            # selected diet variables and foraging
                            c(7, 9, 10, 11, 12, 13, 41, 52), 
                            # selected activity variables and body mass and foraging
                            c(52, 19, 20, 21), # activity and foraging
                            c(52, 42, 43, 44, 45, 46, 47, 48, 41),   
                            # PCA for diet, and body mass and foraging
                            c(52, 42, 43, 44, 45, 46, 47, 48, 19, 20, 21, 41), 
                            # PCA diet, and activity, body mass, and foraging
                            c(7, 9, 10, 11, 12, 13, 19, 20, 21, 41, 52)
                            # selected diet, activity and body mass and foraging
                            )
test_errors = rep(0, length(mammal_knn_variables))

for(i in 1:length(mammal_knn_variables)){
  var = mammal_knn_variables[[i]]
  mammal_knn = knn(mammal_knn_train_df[,var],
                 mammal_knn_test_df[,var],
                 mammal_knn_train_df[,38], k=14)
  test_errors[i] = mean(mammal_knn != mammal_knn_test_df$redlistCategory)
}

which.min(test_errors)
mammal_knn_variables[[which.min(test_errors)]]

# Best Variables: Selected Diet + Activity Variables 

```

```{r mammal prediction and error rate}

mean(mammal_knn != mammal_knn_test_df$redlistCategory)
table(preds = mammal_knn, truth = mammal_knn_test_df$redlistCategory)

# Error rate = 0.311

```

### Hyperparameter Tuning

```{r mammal k value selection}

test_errors = rep(0, 25)
for(i in 1:25){
  mammal_knn = knn(mammal_knn_train_df[,c(7, 9, 10, 11, 12, 13, 19, 20, 21)],
                 mammal_knn_test_df[,c(7, 9, 10, 11, 12, 13, 19, 20, 21)],
                 mammal_knn_train_df[,38], k=i)
  test_errors[i] = mean(mammal_knn != mammal_knn_test_df$redlistCategory)
}

which.min(test_errors)

```

### Best Model

```{r mammal best knn model}

mammal_knn = knn(mammal_knn_train_df[,c(7, 9, 10, 11, 12, 13, 19, 20, 21)],
                 mammal_knn_test_df[,c(7, 9, 10, 11, 12, 13, 19, 20, 21)],
                 mammal_knn_train_df[,38], k=14)
mean(mammal_knn != mammal_knn_test_df$redlistCategory)

# Error rate = 0.305

```

## Bird K-Nearest Neighbor

### Format Variables

```{r bird change factors to numeric}

bird_knn_train_df = bird_train_df
bird_knn_test_df = bird_test_df

# Change factor variables to numeric
bird_knn_train_df = bird_knn_train_df %>% 
  mutate(
    Nocturnal = as.numeric(Nocturnal)
  )

bird_knn_test_df = bird_knn_test_df %>% 
  mutate(
    Nocturnal = as.numeric(Nocturnal)
  )

```

### Variable Selection
Explanatory variables: Body Mass, Diet, Activity, Foraging
```{r bird knn variable selection}

# Commented out variable groups had too many ties
bird_knn_variables = list(#c(12:21), # all diet variables
                          c(37,57), # activity and body mass
                          #c(12:21, 37), # all diet and activity variables
                          c(12:21, 57), # all diet and body mass
                          c(12:21, 37, 57), # all diet and activity and body mass
                          c(26:33), # foraging variables
                          c(26:33, 12:21), # diet and foraging
                          c(26:33, 57), # foraging and body mass
                          c(26:33, 12:21, 37, 57), 
                          # foraging, body mass, activity, and diet
                          c(75:91), # PCA for diet and foraing together
                          c(75:91, 57), 
                          # PCA for diet and foraging together and body mass
                          c(75:91, 57, 37)
                          # PCA for diet + foraging, activity, and body mass
                        )
test_errors = rep(0, length(bird_knn_variables))

for(i in 1:length(bird_knn_variables)){
  var = bird_knn_variables[[i]]
  bird_knn = knn(bird_knn_train_df[,var],
                 bird_knn_test_df[,var],
                 bird_knn_train_df[,54], k=14)
  test_errors[i] = mean(bird_knn != bird_knn_test_df$redlistCategory)
}

which.min(test_errors)
bird_knn_variables[[which.min(test_errors)]]

# Best Variables: Foraging variables

```

```{r bird prediction and error rate}

mean(bird_knn != bird_knn_test_df$redlistCategory)
table(preds = bird_knn, truth = bird_knn_test_df$redlistCategory)

# Error rate = 0.223

```

### Hyperparameter Tuning

```{r bird k value selection}

test_errors = rep(0, 25)
for(i in 1:25){
  bird_knn = knn(bird_knn_train_df[,c(26:33)],
                 bird_knn_test_df[,c(26:33)],
                 bird_knn_train_df[,54], k=i)
  test_errors[i] = mean(bird_knn != bird_knn_test_df$redlistCategory)
}

which.min(test_errors)

```

### Best Model

```{r mammal best knn model}

bird_knn = knn(bird_knn_train_df[,c(26:33)],
                 bird_knn_test_df[,c(26:33)],
                 bird_knn_train_df[,54], k=12)
mean(bird_knn != bird_knn_test_df$redlistCategory)

# Error rate = 0.222

```

# 5: Classification Tree

## Mammal Classification Tree

```{r mammal change variable types}

mammal_train_df$redlistCategory = as.factor(mammal_train_df$redlistCategory)
mammal_test_df$redlistCategory = as.factor(mammal_test_df$redlistCategory)

```

```{r mammal class tree}

mammal_tree = tree(redlistCategory ~ log_bodymass + ForStrat.Value + 
                   Activity.Crepuscular + Activity.Diurnal + Activity.Nocturnal + 
                   Diet.Inv + Diet.Vend + Diet.Vect + Diet.Vfish + Diet.Vunk + 
                   Diet.Scav + Diet.Fruit + Diet.PlantO, 
                   mammal_train_df)

```

```{r mammal tree assessment}

summary(mammal_tree)

plot(mammal_tree)
text(mammal_tree, pretty = 0)

```

# 6: Bagged Trees

## Mammal Bagged Trees

### Variable Selection

```{r}
#Using variables selected for LDA
test_errors = rep(0, length(mammal_lda_variables))



for(i in 1:length(mammal_lda_variables)){
  var = mammal_lda_variables[[i]]
  mammal_lda = randomForest(as.factor(redlistCategory) ~ .,
                   data = mammal_train_df[,var],
                   mtry = (length(var)-1))
  bag_pred = predict(mammal_lda,newdata=mammal_test_df[,var])
  test_errors[i] = mean(bag_pred != mammal_test_df$redlistCategory)
}

which.min(test_errors)
mammal_lda_variables[[which.min(test_errors)]]


```

### Best Model

```{r}
var = mammal_lda_variables[[2]]
mammal_lda = randomForest(as.factor(redlistCategory) ~ .,
                   data = mammal_train_df[,var],
                   mtry = (length(var)-1))
bag_pred = predict(mammal_lda,newdata=mammal_test_df[,var])
mean(bag_pred != mammal_test_df$redlistCategory)
table(bag_pred, mammal_test_df$redlistCategory)

colnames(mammal_train_df)[mammal_lda_variables[[2]]]

# test error 0.3187325
```

## Bird Bagged Trees

### Variable Selection

```{r}
#Using variables selected for LDA
test_errors = rep(0, length(bird_lda_variables))



for(i in 1:length(bird_lda_variables)){
  var = bird_lda_variables[[i]]
  bird_lda = randomForest(as.factor(redlistCategory) ~ .,
                   data = bird_train_df[,var],
                   mtry = (length(var)-1))
  bag_pred = predict(bird_lda,newdata=bird_test_df[,var])
  test_errors[i] = mean(bag_pred != bird_test_df$redlistCategory)
}

which.min(test_errors)
bird_lda_variables[[which.min(test_errors)]]
```

### Best Model

```{r}
var = bird_lda_variables[[7]]
bird_lda = randomForest(as.factor(redlistCategory) ~ .,
                   data = bird_train_df[,var],
                   mtry = (length(var)-1))
bag_pred = predict(bird_lda,newdata=bird_test_df[,var])
mean(bag_pred != bird_test_df$redlistCategory)
table(bag_pred, bird_test_df$redlistCategory)

colnames(bird_train_df)[bird_lda_variables[[7]]]

#test error 0.2358825

```

# 7: Random Forests

## Mammal Random Forests

### Variable Selection

```{r}
#Using variables selected for LDA
test_errors = rep(0, length(mammal_lda_variables))


set.seed(10)
for(i in 1:length(mammal_lda_variables)){
  var = mammal_lda_variables[[i]]
  mammal_rf = randomForest(as.factor(redlistCategory) ~ .,
                   data = mammal_train_df[,var],
                   mtry = round(sqrt(length(var)-1))
                   )
  bag_pred = predict(mammal_rf,newdata=mammal_test_df[,var])
  test_errors[i] = mean(bag_pred != mammal_test_df$redlistCategory)
}

which.min(test_errors)
mammal_lda_variables[[which.min(test_errors)]]

mammal_rf_test_errors = test_errors
```

### Best Model

```{r}
set.seed(10)
var = mammal_lda_variables[[10]]
mammal_rf = randomForest(as.factor(redlistCategory) ~ .,
                   data = mammal_train_df[,var],
                   mtry = round(sqrt(length(var)-1))
                   )
bag_pred = predict(mammal_rf,newdata=mammal_test_df[,var])
mean(bag_pred != mammal_test_df$redlistCategory)
table(bag_pred, mammal_test_df$redlistCategory)

colnames(mammal_train_df)[mammal_lda_variables[[10]]]

varImpPlot(mammal_rf)

#test error 0.3117428

```

Based on this plot, the body mass is the most important variable.

## Bird Random Forest

### Variable Selection

```{r}
test_errors = rep(0, length(bird_lda_variables))

set.seed(10)
for(i in 1:length(bird_lda_variables)){
  var = bird_lda_variables[[i]]
  bird_rf = randomForest(as.factor(redlistCategory) ~ .,
                   data = bird_train_df[,var],
                   mtry = round(sqrt(length(var)))
                   )
  bag_pred = predict(bird_rf,newdata=bird_test_df[,var])
  test_errors[i] = mean(bag_pred != bird_test_df$redlistCategory)
}

which.min(test_errors)
bird_lda_variables[[which.min(test_errors)]]

bird_rf_test_errors = test_errors
```

### Best Model

```{r}
set.seed(10)
var = bird_lda_variables[[7]]
bird_rf = randomForest(as.factor(redlistCategory) ~ .,
                   data = bird_train_df[,var],
                   mtry = round(sqrt(length(var)-1))
                   )
bag_pred = predict(bird_rf,newdata=bird_test_df[,var])
mean(bag_pred != bird_test_df$redlistCategory)
table(bag_pred, bird_test_df$redlistCategory)

colnames(bird_train_df)[bird_lda_variables[[7]]]

varImpPlot(bird_rf)

```

# 8: Boosted Forests

# 9: Neural Networks

## Mammal Neural Network

### Variable Selection

```{r}

mammal_nn_variables = list(c(38,4, 5, 6, 7, 8, 9, 10, 11, 12, 13), #all diet variables
                            c(38,7, 9, 10, 11, 12, 13),                  #selected diet variables
                            c(38,41),                               #log body mass
                            c(38,19, 20, 21, 41),                   #activity and body mass
                            c(38,4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 20, 21), #all diet and activity variables
                            c(38,4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 41),         #all diet and body mass
                            c(38,41, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 20, 21), #all diet and activity and body mass
                            c(38,7, 9, 10, 11, 12, 13, 41), #selected activity variables and body mass
                            c(38,7, 9, 10, 11, 12, 13, 19, 20, 21), #selected diet and activity
                            c(38,7, 9, 10, 11, 12, 13, 19, 20, 21, 41), #selected diet, activity and body mass
                            c(38,42, 43, 44, 45, 46, 47, 48), # 7 PC for diet
                            c(38,42, 43, 44, 45, 46, 47, 48, 41), # PCA for diet and diet
                            c(38,42, 43, 44, 45, 46, 47, 48, 19, 20, 21), # PCA for diet and activity
                            c(38,42, 43, 44, 45, 46, 47, 48, 19, 20, 21, 41), # PCA for diet, activity, and body mass
                            c(38,7, 9, 10, 11, 12, 13, 16),     #selected diet variables and foraging
                            c(38,7, 9, 10, 11, 12, 13, 41, 16), #selected activity variables and body mass and foraging
                            c(38, 16, 19, 20, 21), # activity and foraging
                            c(38, 16, 42, 43, 44, 45, 46, 47, 48, 41),   # PCA for diet, and body mass and foraging
                            c(38, 16, 42, 43, 44, 45, 46, 47, 48, 19, 20, 21, 41), #PCAdiet, and activity, body mass, and foraging
                            c(38,7, 9, 10, 11, 12, 13, 19, 20, 21, 41, 16)#selected diet, activity and body mass and foraging
                        
                            )  
test_errors = rep(0, length(mammal_nn_variables))

for(i in 1:length(mammal_nn_variables)){
  var = mammal_nn_variables[[i]]
  mammal_nn = nnet(redlistCategory ~ .,
                   data = mammal_train_df[,var], size = 20, linout = FALSE)
  nn_pred = predict(mammal_nn, newdata=mammal_test_df[,var], type = "class")
  test_errors[i] = mean(nn_pred != mammal_test_df$redlistCategory)
}

which.min(test_errors)
mammal_nn_variables[[which.min(test_errors)]]

```

```{r}

var = mammal_nn_variables[[4]]
mammal_nn = nnet(redlistCategory ~ .,
                   data = mammal_train_df[,var], size = 20, linout = FALSE)
nn_pred = predict(mammal_nn, newdata=mammal_test_df[,var], type = "class")
mean(nn_pred != mammal_test_df$redlistCategory)

# Error rate = 0.3140

```

### Choosing Number of Hidden Units

```{r}

test_errors = rep(0, 20)

for(i in seq(5, 100, 5)){
  var = mammal_nn_variables[[4]]
  mammal_nn = nnet(redlistCategory ~ .,
                   data = mammal_train_df[,var], size = i, linout = FALSE)
  nn_pred = predict(mammal_nn, newdata=mammal_test_df[,var], type = "class")
  test_errors[i] = mean(nn_pred != mammal_test_df$redlistCategory)
}

which.min(test_errors)
seq(5, 100, 5)[[which.min(test_errors)]]

```

### Best Model

```{r}

var = mammal_nn_variables[[4]]
mammal_nn = nnet(redlistCategory ~ .,
                   data = mammal_train_df[,var], size = 5, linout = FALSE)
nn_pred = predict(mammal_nn, newdata=mammal_test_df[,var], type = "class")
mean(nn_pred != mammal_test_df$redlistCategory)

# Error rate = 0.312

```

## Bird Neural Network

### Variable Selection

```{r}

bird_train_df = bird_train_df %>% 
  mutate(redlistCategory = as.factor(redlistCategory))

bird_test_df = bird_test_df %>% 
  mutate(redlistCategory = as.factor(redlistCategory))

bird_nn_variables = list(c(54, 12:21), # all diet variables
                         c(54, 37,57), # activity and body mass
                         c(54, 12:21, 37), # all diet and activity variables
                         c(54, 12:21, 57), # all diet and body mass
                         c(54, 12:21, 37, 57), # all diet and activity and body mass
                         c(54, 26:33), # foraging variables
                         c(54, 26:33, 12:21), # diet and foraging
                         c(54, 26:33, 57), # foraging and body mass
                         c(54, 26:33, 12:21, 37, 57), 
                          # foraging, body mass, activity, and diet
                         c(54, 75:91), # PCA for diet and foraing together
                         c(54, 75:91, 57), 
                          # PCA for diet and foraging together and body mass
                         c(54, 75:91, 57, 37)
                          # PCA for diet + foraging, activity, and body mass
                        )
test_errors = rep(0, length(bird_nn_variables))

for(i in 1:length(bird_nn_variables)){
  var = bird_nn_variables[[i]]
  bird_nn = nnet(redlistCategory ~ .,
                   data = bird_train_df[,var], size = 20, linout = FALSE)
  nn_pred = predict(bird_nn, newdata=bird_test_df[,var], type = "class")
  test_errors[i] = mean(nn_pred != bird_test_df$redlistCategory)
}

which.min(test_errors)
bird_nn_variables[[which.min(test_errors)]]

```

```{r}

var = bird_nn_variables[[4]]
bird_nn = nnet(redlistCategory ~ .,
                   data = bird_train_df[,var], size = 20, linout = FALSE)
nn_pred = predict(bird_nn, newdata=bird_test_df[,var], type = "class")
mean(nn_pred != bird_test_df$redlistCategory)

# Error rate = 0.228

```

### Choosing Number of Hidden Units

```{r}

test_errors = rep(0, 10)

for(i in seq(5, 50, 5)){
  var = bird_nn_variables[[4]]
  bird_nn = nnet(redlistCategory ~ .,
                   data = bird_train_df[,var], size = i, linout = FALSE)
  nn_pred = predict(bird_nn, newdata=bird_test_df[,var], type = "class")
  test_errors[i] = mean(nn_pred != bird_test_df$redlistCategory)
}

which.min(test_errors)
seq(5, 70, 5)[[which.min(test_errors)]]

```

### Best Model

```{r}

var = bird_nn_variables[[4]]
bird_nn = nnet(redlistCategory ~ .,
                   data = bird_train_df[,var], size = 5, linout = FALSE)
nn_pred = predict(bird_nn, newdata=bird_test_df[,var], type = "class")
mean(nn_pred != bird_test_df$redlistCategory)

# Error rate = 0.222

```

## Bird Random Forest

# 8: Boosted Forests

## Mammal Boosted Forest

### Variable Selection

Boosted forests are computationally inefficient, so we are using the best half of the sets of variable identified by the random forests and using ony 500 trees.

```{r}
#selecting variable sets to use
#variable_sets = c(1:20)[mammal_rf_test_errors<median(mammal_rf_test_errors)]

#Using variables selected for LDA
test_errors = rep(0, length(mammal_lda_variables))


set.seed(10)
for(i in 1:length(mammal_lda_variables)){ #using selected variable sets
  var = mammal_lda_variables[[i]]
  mammal_boost = gbm(as.factor(redlistCategory) ~ .,
                      data=mammal_train_df[,var],n.trees=500,distribution = "multinomial",
                     interaction.depth=4,shrinkage = 0.1)
    
  
  pred_tmp = predict(mammal_boost,newdata = mammal_test_df[,var],n.trees = 500)
  tmp_max = apply(pred_tmp, 1, which.max)
  pred_boosted=c("Endangered","Least Concern", "Near Threatened","Vulnerable")[tmp_max]

  test_errors[i] = mean(pred_boosted!= mammal_test_df$redlistCategory)
}

#making any test error
test_errors[test_errors==0]=1

which.min(test_errors)
mammal_lda_variables[[which.min(test_errors)]]
#shrinkage

```

##### Tuning Parameters

```{r}

test_errors = rep(0, 5)
var = mammal_lda_variables[[1]] #best set from above
for (i in 1:5){
  mammal_boost = gbm(as.factor(redlistCategory) ~ .,
                      data=mammal_train_df[,var],n.trees=1000,distribution = "multinomial",
                     interaction.depth=4,shrinkage = c(1,0.1,0.01,0.001,0.0001)[i])
  pred_tmp = predict(mammal_boost,newdata = mammal_test_df[,var],n.trees = 500)
  tmp_max = apply(pred_tmp, 1, which.max)
  pred_boosted=c("Endangered","Least Concern", "Near Threatened","Vulnerable")[tmp_max]
}

which.min(test_errors)
c(1,0.1,0.01,0.001,0,0001)[which.min(test_errors)]
```

### Best Model

```{r}
mammal_boost = gbm(as.factor(redlistCategory) ~ .,
                      data=mammal_train_df[,var],n.trees=1000,distribution = "multinomial",
                     interaction.depth=4,shrinkage = 1)

colnames(mammal_train_df)[mammal_lda_variables[[10]]]

```

# 10: Support Vector Machines

## Mammal Support Vector Machines

### Variable Selection

#### Using a Linear Function

```{r}
#Using variables selected for LDA
test_errors = rep(0, length(mammal_lda_variables))


set.seed(10)
for(i in 1:length(mammal_lda_variables)){
  var = mammal_lda_variables[[i]]
  
  if(i==3) {
    test_errors[i]=1
    next
  }
  mammal_svm=svm(as.factor(redlistCategory)~., 
                  data=mammal_train_df[,var],kernel="linear", gamma=1,cost=1)
    
  pred_svm = predict(mammal_svm,newdata=mammal_test_df[,var])
  #best_params[i,] = mammal_svm$best.parameters
  test_errors[i] = mean(pred_svm != mammal_test_df$redlistCategory)
  
}

which.min(test_errors)
mammal_lda_variables[[which.min(test_errors)]]

colnames(mammal_train_df[mammal_lda_variables[[which.min(test_errors)]]])

```

#### Tuning Parameters
```{r}

var = mammal_lda_variables[[2]]
mammal_svm = tune(svm, as.factor(redlistCategory)~., 
                  data=mammal_train_df[,var],kernel="linear",
                  ranges=list(cost=c(0.1,1,10),
                  gamma=c(0.5,1,2,3,4)))

pred_svm = predict(mammal_svm$best.model,newdata=mammal_test_df[,var])

#Misclassification rate for endangered
sum(pred_svm != mammal_test_df$redlistCategory & mammal_test_df$redlistCategory == "Endangered" )/sum(mammal_test_df$redlistCategory == "Endangered")

mean(pred_svm != mammal_test_df$redlistCategory)
table(pred_svm, mammal_test_df$redlistCategory)

```
Classified everything as least concern.

#### Using a Radial Function
```{r}
#Using variables selected for LDA
test_errors = rep(0, length(mammal_lda_variables))


set.seed(10)
for(i in 1:length(mammal_lda_variables)){
  var = mammal_lda_variables[[i]]
  
  if(i==3) {
    test_errors[i]=1
    next
  }
  mammal_svm=svm(as.factor(redlistCategory)~., 
                  data=mammal_train_df[,var],kernel="radial", gamma=1,cost=1)
    
  pred_svm = predict(mammal_svm,newdata=mammal_test_df[,var])
  #best_params[i,] = mammal_svm$best.parameters
  test_errors[i] = mean(pred_svm != mammal_test_df$redlistCategory)
  
}

which.min(test_errors)
mammal_lda_variables[[which.min(test_errors)]]

colnames(mammal_train_df[mammal_lda_variables[[which.min(test_errors)]]])

```

### Tuning Parameters

```{r}
var = mammal_lda_variables[[11]]
mammal_svm = tune(svm, as.factor(redlistCategory)~., 
                  data=mammal_train_df[,var],kernel="radial",
                  ranges=list(cost=c(0.1,1,10),
                  gamma=c(0.5,1,2,3,4)))

pred_svm = predict(mammal_svm$best.model,newdata=mammal_test_df[,var])

mammal_svm$best.parameters

#Misclassification rate for endangered
sum(pred_svm != mammal_test_df$redlistCategory & mammal_test_df$redlistCategory == "Endangered" )/sum(mammal_test_df$redlistCategory == "Endangered")

mean(pred_svm != mammal_test_df$redlistCategory)
table(pred_svm, mammal_test_df$redlistCategory)


#test error 0.304753
```
Best parameters have cost of 1 and gamma of 0.5.

### Best Model

```{r}
var = mammal_lda_variables[[11]]
mammal_svm=svm(as.factor(redlistCategory) ~., 
                  data=mammal_train_df[,var],kernel="radial", gamma=0.5,cost=1)


mean(pred_svm != mammal_test_df$redlistCategory)
table(pred_svm, mammal_test_df$redlistCategory)
colnames(mammal_train_df[var])

```

## Bird Support Vector Machine

#### Using a Linear Function

```{r, eval=FALSE}
#Using variables selected for LDA
test_errors = rep(0, length(bird_lda_variables))


set.seed(10)
for(i in 1:length(bird_lda_variables)){
  var = bird_lda_variables[[i]]
  
  if(i==3) {
    test_errors[i]=1
    next
  }
  bird_svm=svm(as.factor(redlistCategory)~., 
                  data=bird_train_df[,var],kernel="linear", gamma=1,cost=1)
    
  pred_svm = predict(bird_svm,newdata=bird_test_df[,var])
  #best_params[i,] = bird_svm$best.parameters
  test_errors[i] = mean(pred_svm != bird_test_df$redlistCategory)
  
}

which.min(test_errors)
bird_lda_variables[[which.min(test_errors)]]

colnames(bird_train_df[bird_lda_variables[[which.min(test_errors)]]])

```

#### Tuning Parameters
```{r, eval=FALSE}

var = bird_lda_variables[[1]] #best from above
bird_svm = tune(svm, as.factor(redlistCategory)â¼., 
                  data=bird_train_df[,var],kernel="linear",
                  ranges=list(cost=c(0.1,1,10),
                  gamma=c(0.5,1,2,3,4)))

pred_svm = predict(bird_svm$best.model,newdata=bird_test_df[,var])

#Misclassification rate for endangered
sum(pred_svm != bird_test_df$redlistCategory & bird_test_df$redlistCategory == "Endangered" )/sum(bird_test_df$redlistCategory == "Endangered")

mean(pred_svm != bird_test_df$redlistCategory)
table(pred_svm, bird_test_df$redlistCategory)

```
Classifies everything as least concern, so not including.

#### Using a Radial Function
```{r}
#Using variables selected for LDA
test_errors = rep(0, length(bird_lda_variables))


set.seed(10)
for(i in 1:length(bird_lda_variables)){
  var = bird_lda_variables[[i]]
  
  if(i==3) {
    test_errors[i]=1
    next
  }
  bird_svm=svm(as.factor(redlistCategory)~., 
                  data=bird_train_df[,var],kernel="radial", gamma=1,cost=1)
    
  pred_svm = predict(bird_svm,newdata=bird_test_df[,var])
  #best_params[i,] = bird_svm$best.parameters
  test_errors[i] = mean(pred_svm != bird_test_df$redlistCategory)
  
}

which.min(test_errors)
bird_lda_variables[[which.min(test_errors)]]

colnames(bird_train_df[bird_lda_variables[[which.min(test_errors)]]])

```

### Tuning Parameters

```{r}
var = bird_lda_variables[[9]]
bird_svm = tune(svm, as.factor(redlistCategory)â¼., 
                  data=bird_train_df[,var],kernel="radial",
                  ranges=list(cost=c(0.1,1,10),
                  gamma=c(0.5,1,2,3,4)))

pred_svm = predict(bird_svm$best.model,newdata=bird_test_df[,var])

bird_svm$best.parameters

#Misclassification rate for endangered
sum(pred_svm != bird_test_df$redlistCategory & bird_test_df$redlistCategory == "Endangered" )/sum(bird_test_df$redlistCategory == "Endangered")

mean(pred_svm != bird_test_df$redlistCategory)
table(pred_svm, bird_test_df$redlistCategory)

#test error 
```
Best parameters have cost of 0.1 and gamma of 0.5.

### Best Model

```{r}
var = bird_lda_variables[[9]]
bird_svm=svm(as.factor(redlistCategory)~., 
                  data=bird_train_df[,var],kernel="radial", gamma=0.1,cost=0.1)


mean(pred_svm != bird_test_df$redlistCategory)
table(pred_svm, bird_test_df$redlistCategory)
colnames(bird_train_df[var])


```
test eror 0.227339


# Model Comparison

## Half Training Data and Half Test Data 

### Best Mammal Models

```{r}

# Logistic Regression
var = mammal_log_variables[[16]]
mammal_log = glm(redlistCategory ~ .,
                   data = mammals_log_train_df[,var])
log_prob = predict(mammal_log, newdata=mammals_log_test_df[,var], type = "response")
log_pred = rep(0, 2146)
log_pred[log_prob > 0.5] = 1
mean(log_pred != mammals_log_test_df$redlistCategory)
table(log_pred, mammals_log_test_df$redlistCategory)

# Linear Discriminant Analysis
mammal_lda = lda(redlistCategory ~ .,
                   data = mammal_train_df[,mammal_lda_variables[[14]]])
lda_pred = predict(mammal_lda,newdata=mammal_test_df[,mammal_lda_variables[[14]]])
mean(lda_pred$class != mammal_test_df$redlistCategory)
table(pred=lda_pred$class,truth=mammal_test_df$redlistCategory)

# Quadratic Discriminant Analysis
mammal_qda = qda(redlistCategory ~ .,
                   data = mammal_train_df[,mammal_qda_variables[[3]]])
qda_pred = predict(mammal_qda,newdata=mammal_test_df[,mammal_qda_variables[[3]]])
mean(qda_pred$class != mammal_test_df$redlistCategory)
table(pred=qda_pred$class,truth=mammal_test_df$redlistCategory)

# K Nearest Neighbors
mammal_knn = knn(mammal_knn_train_df[,c(7, 9, 10, 11, 12, 13, 19, 20, 21)],
                 mammal_knn_test_df[,c(7, 9, 10, 11, 12, 13, 19, 20, 21)],
                 mammal_knn_train_df[,38], k=14)
mean(mammal_knn != mammal_knn_test_df$redlistCategory)
table(mammal_knn, mammal_knn_test_df$redlistCategory)

# Bagged Tree
var = mammal_lda_variables[[2]]
mammal_lda = randomForest(as.factor(redlistCategory) ~ .,
                   data = mammal_train_df[,var],
                   mtry = (length(var)-1))
bag_pred = predict(mammal_lda,newdata=mammal_test_df[,var])
mean(bag_pred != mammal_test_df$redlistCategory)
table(bag_pred,mammal_test_df$redlistCategory)

# Random Forest
set.seed(10)
var = mammal_lda_variables[[10]]
mammal_rf = randomForest(as.factor(redlistCategory) ~ .,
                   data = mammal_train_df[,var],
                   mtry = round(sqrt(length(var)-1))
                   )
bag_pred = predict(mammal_rf,newdata=mammal_test_df[,var])
mean(bag_pred != mammal_test_df$redlistCategory)
table(bag_pred,mammal_test_df$redlistCategory)

# Neural Network
var = mammal_nn_variables[[4]]
mammal_nn = nnet(as.factor(redlistCategory) ~ .,
                   data = mammal_train_df[,var], size = 5, linout = FALSE)
nn_pred = predict(mammal_nn, newdata=mammal_test_df[,var], type = "class")
mean(nn_pred != mammal_test_df$redlistCategory)
table(nn_pred, mammal_test_df$redlistCategory)

# Support Vector Machine
var = mammal_lda_variables[[11]]
mammal_svm=svm(as.factor(redlistCategory) ~., 
                  data=mammal_train_df[,var],kernel="radial", gamma=0.5,cost=1)
pred_svm = predict(mammal_svm,newdata = mammal_test_df[,var])
mean(pred_svm != mammal_test_df$redlistCategory)
table(pred_svm,mammal_test_df$redlistCategory)
```

Mammal Model Error Rates
Logistic Regression = 0.280
LDA = 0.309
QDA = 0.329
KNN = 0.305
Bagged Tree = 0.319
Random Forest = 0.312
Neural Network = 0.312
SVM = 0.315

The best model to predict the redlist status of a mammal species based on its Elton traits was a Logistic Regression.  

### Best Bird Models

```{r}

# Linear Discriminant Analysis
bird_lda = lda(redlistCategory ~ .,
                   data = bird_train_df[,bird_lda_variables[[7]]])
lda_pred = predict(bird_lda,newdata=bird_test_df[,bird_lda_variables[[7]]])
mean(lda_pred$class != bird_test_df$redlistCategory)
table(pred=lda_pred$class,truth=bird_test_df$redlistCategory)

# Quadratic Discriminant Analysis
bird_qda = qda(redlistCategory ~ .,
                   data = bird_train_df[,bird_qda_variables[[2]]])
qda_pred = predict(bird_qda,newdata=bird_test_df[,bird_qda_variables[[2]]])
mean(qda_pred$class != bird_test_df$redlistCategory)
table(pred=qda_pred$class,truth=bird_test_df$redlistCategory)

# K Nearest Neighbor
bird_knn = knn(bird_knn_train_df[,c(26:33)],
                 bird_knn_test_df[,c(26:33)],
                 bird_knn_train_df[,54], k=12)
mean(bird_knn != bird_knn_test_df$redlistCategory)
table(bird_knn,bird_knn_test_df$redlistCategory)

# Bagged Tree
var = bird_lda_variables[[7]]
bird_lda = randomForest(as.factor(redlistCategory) ~ .,
                   data = bird_train_df[,var],
                   mtry = (length(var)-1))
bag_pred = predict(bird_lda,newdata=bird_test_df[,var])
mean(bag_pred != bird_test_df$redlistCategory)
table(bag_pred, bird_test_df$redlistCategory)

# Random Forest
set.seed(10)
var = bird_lda_variables[[7]]
bird_rf = randomForest(as.factor(redlistCategory) ~ .,
                   data = bird_train_df[,var],
                   mtry = round(sqrt(length(var)-1))
                   )
bag_pred = predict(bird_rf,newdata=bird_test_df[,var])
mean(bag_pred != bird_test_df$redlistCategory)
table(bag_pred, bird_test_df$redlistCategory)

# Neural Network
var = bird_nn_variables[[4]]
bird_nn = nnet(redlistCategory ~ .,
                   data = bird_train_df[,var], size = 5, linout = FALSE)
nn_pred = predict(bird_nn, newdata=bird_test_df[,var], type = "class")
mean(nn_pred != bird_test_df$redlistCategory)
table(nn_pred, bird_test_df$redlistCategory)

# Support Vector Machines
var = bird_lda_variables[[9]]
bird_svm=svm(as.factor(redlistCategory)~., 
                  data=bird_train_df[,var],kernel="radial", gamma=0.1,cost=0.1)
mean(pred_svm != bird_test_df$redlistCategory)
table(pred_svm, bird_test_df$redlistCategory)

```

Bird Model Variables
LDA = 0.227
QDA = 0.228
KNN = 0.222
Bagged Tree = 0.236
Random Forest = 0.225
Neural Network = 0.222
SVM = 0.222

Bird Model Error Rates 
LDA = 0.227
QDA = 0.228
KNN = 0.222
Bagged Tree = 0.236
Random Forest = 0.225
Neural Network = 0.222
SVM = 0.222

Neural Networks, Support Vector Machines, and K-Nearest-Neighbors were all equivalent in predicting the redlist status of a bird species. 

## Two-Thirds Training Data and One-Third Test Data

```{r creating test and training datasets 2}

# Creating indices for training sets
set.seed(10)
train_mammal2 = sample(1:nrow(mammal_df), size = round(nrow(mammal_df)*0.667))
train_bird2 = sample(1:nrow(bird_df), size = round(nrow(bird_df)*0.667))

# Creating training and test sets
mammal_train2_df = mammal_df[train_mammal,]
mammal_test2_df = mammal_df[-train_mammal,]

bird_train2_df = bird_df[train_bird,]
bird_test2_df = bird_df[-train_bird,]

```

### Mammal Models 

```{r}

# Create separate logistic regression dataframe
mammals_log_train2_df = mammal_train2_df
mammals_log_test2_df = mammal_test2_df

# Change Response to Binary
mammals_log_train2_df = mammals_log_train2_df %>% 
  mutate(
    redlistCategory = case_when(
      redlistCategory == "Endangered" ~ 1,
      redlistCategory == "Near Threatened" ~ 1,
      redlistCategory == "Vulnerable" ~ 1,
      TRUE ~ 0
    )
  )

mammals_log_test2_df = mammals_log_test2_df %>% 
  mutate(
    redlistCategory = case_when(
      redlistCategory == "Endangered" ~ 1,
      redlistCategory == "Near Threatened" ~ 1,
      redlistCategory == "Vulnerable" ~ 1,
      TRUE ~ 0
    )
  )

# Logistic Regression
var = mammal_log_variables[[16]]
mammal_log = glm(redlistCategory ~ .,
                   data = mammals_log_train2_df[,var])
log_prob = predict(mammal_log, newdata=mammals_log_test2_df[,var], type = "response")
log_pred = rep(0, 2146)
log_pred[log_prob > 0.5] = 1
mean(log_pred != mammals_log_test2_df$redlistCategory)


```

```{r}

# Linear Discriminant Analysis
mammal_lda = lda(redlistCategory ~ .,
                   data = mammal_train2_df[,mammal_lda_variables[[14]]])
lda_pred = predict(mammal_lda,newdata=mammal_test2_df[,mammal_lda_variables[[14]]])
mean(lda_pred$class != mammal_test2_df$redlistCategory)

# Quadratic Discriminant Analysis
mammal_qda = qda(redlistCategory ~ .,
                   data = mammal_train2_df[,mammal_qda_variables[[3]]])
qda_pred = predict(mammal_qda,newdata=mammal_test2_df[,mammal_qda_variables[[3]]])
mean(qda_pred$class != mammal_test2_df$redlistCategory)

```

```{r}

# Create separate dataframes for KNN
mammal_knn_train2_df = mammal_train2_df
mammal_knn_test2_df = mammal_test2_df

# Change factor variables to numeric
mammal_knn_train2_df = mammal_knn_train2_df %>% 
  mutate(
    Activity.Diurnal = as.numeric(Activity.Diurnal),
    Activity.Crepuscular = as.numeric(Activity.Crepuscular),
    Activity.Nocturnal = as.numeric(Activity.Nocturnal),
    
    for_strat_num = case_when(
      ForStrat.Value == "A" ~ 1,
      ForStrat.Value == "Ar" ~ 2,
      ForStrat.Value == "G" ~ 3,
      ForStrat.Value == "M" ~ 4,
      ForStrat.Value == "S" ~ 5
      ),
    for_strat_num = as.numeric(for_strat_num)
  )

mammal_knn_test2_df = mammal_knn_test2_df %>% 
  mutate(
    Activity.Diurnal = as.numeric(Activity.Diurnal),
    Activity.Crepuscular = as.numeric(Activity.Crepuscular),
    Activity.Nocturnal = as.numeric(Activity.Nocturnal),
    
    for_strat_num = case_when(
      ForStrat.Value == "A" ~ 1,
      ForStrat.Value == "Ar" ~ 2,
      ForStrat.Value == "G" ~ 3,
      ForStrat.Value == "M" ~ 4,
      ForStrat.Value == "S" ~ 5
      ),
    for_strat_num = as.numeric(for_strat_num)
  )

# K Nearest Neighbors
mammal_knn = knn(mammal_knn_train2_df[,c(7, 9, 10, 11, 12, 13, 19, 20, 21)],
                 mammal_knn_test2_df[,c(7, 9, 10, 11, 12, 13, 19, 20, 21)],
                 mammal_knn_train2_df[,38], k=14)
mean(mammal_knn != mammal_knn_test2_df$redlistCategory)

```

```{r}

# Bagged Tree
var = mammal_lda_variables[[2]]
mammal_lda = randomForest(as.factor(redlistCategory) ~ .,
                   data = mammal_train2_df[,var],
                   mtry = (length(var)-1))
bag_pred = predict(mammal_lda,newdata=mammal_test2_df[,var])
mean(bag_pred != mammal_test2_df$redlistCategory)

# Random Forest
set.seed(10)
var = mammal_lda_variables[[10]]
mammal_rf = randomForest(as.factor(redlistCategory) ~ .,
                   data = mammal_train2_df[,var],
                   mtry = round(sqrt(length(var)-1))
                   )
bag_pred = predict(mammal_rf,newdata=mammal_test2_df[,var])
mean(bag_pred != mammal_test2_df$redlistCategory)

```

```{r}
# Neural Network

mammal_train2_df$redlistCategory = as.factor(mammal_train2_df$redlistCategory)
mammal_test2_df$redlistCategory = as.factor(mammal_test2_df$redlistCategory)

var = mammal_nn_variables[[4]]
mammal_nn = nnet(redlistCategory ~ .,
                   data = mammal_train2_df[,var], size = 5, linout = FALSE)
nn_pred = predict(mammal_nn, newdata=mammal_test2_df[,var], type = "class")
mean(nn_pred != mammal_test2_df$redlistCategory)

# Support Vector Machine
var = mammal_lda_variables[[11]]
mammal_svm=svm(as.factor(redlistCategory) ~., 
                  data=mammal_train2_df[,var],kernel="radial", gamma=0.5,cost=1)
mean(pred_svm != mammal_test2_df$redlistCategory)

```

Mammal Model Error Rates:
Logistic Regression = 0.288
LDA = 0.315
QDA = 0.337
KNN = 0.305
Bagged Tree = 0.322
Random Forest = 0.303
Neural Network = 0.311
SVM = 0.325

Logistic regression was the best model at predicting the redlist category of a mammal species. This is the same result from the 50/50 training/test data split. 

### Bird Models 

```{r}

# Linear Discriminant Analysis
bird_lda = lda(redlistCategory ~ .,
                   data = bird_train2_df[,bird_lda_variables[[7]]])
lda_pred = predict(bird_lda,newdata=bird_test2_df[,bird_lda_variables[[7]]])
mean(lda_pred$class != bird_test2_df$redlistCategory)

# Quadratic Discriminant Analysis
bird_qda = qda(redlistCategory ~ .,
                   data = bird_train2_df[,bird_qda_variables[[2]]])
qda_pred = predict(bird_qda,newdata=bird_test2_df[,bird_qda_variables[[2]]])
mean(qda_pred$class != bird_test2_df$redlistCategory)

```

```{r}

# K Nearest Neighbor
bird_knn_train2_df = bird_train2_df
bird_knn_test2_df = bird_test2_df

# Change factor variables to numeric
bird_knn_train2_df = bird_knn_train2_df %>% 
  mutate(
    Nocturnal = as.numeric(Nocturnal)
  )

bird_knn_test2_df = bird_knn_test2_df %>% 
  mutate(
    Nocturnal = as.numeric(Nocturnal)
  )

bird_knn = knn(bird_knn_train2_df[,c(26:33)],
                 bird_knn_test2_df[,c(26:33)],
                 bird_knn_train2_df[,54], k=12)
mean(bird_knn != bird_knn_test2_df$redlistCategory)

```

```{r}

# Bagged Tree
var = bird_lda_variables[[7]]
bird_lda = randomForest(as.factor(redlistCategory) ~ .,
                   data = bird_train2_df[,var],
                   mtry = (length(var)-1))
bag_pred = predict(bird_lda,newdata=bird_test2_df[,var])
mean(bag_pred != bird_test2_df$redlistCategory)

# Random Forest
set.seed(10)
var = bird_lda_variables[[7]]
bird_rf = randomForest(as.factor(redlistCategory) ~ .,
                   data = bird_train2_df[,var],
                   mtry = round(sqrt(length(var)-1))
                   )
bag_pred = predict(bird_rf,newdata=bird_test2_df[,var])
mean(bag_pred != bird_test2_df$redlistCategory)

```

```{r}

# Neural Network
bird_train2_df = bird_train2_df %>% 
  mutate(redlistCategory = as.factor(redlistCategory))

bird_test2_df = bird_test2_df %>% 
  mutate(redlistCategory = as.factor(redlistCategory))

var = bird_nn_variables[[4]]
bird_nn = nnet(redlistCategory ~ .,
                   data = bird_train2_df[,var], size = 5, linout = FALSE)
nn_pred = predict(bird_nn, newdata=bird_test2_df[,var], type = "class")
mean(nn_pred != bird_test2_df$redlistCategory)

# Support Vector Machines
var = bird_lda_variables[[9]]
bird_svm=svm(as.factor(redlistCategory)~., 
                  data=bird_train2_df[,var],kernel="radial", gamma=0.1,cost=0.1)
mean(pred_svm != bird_test2_df$redlistCategory)

```

Bird Model Error Rates:
LDA = 0.223
QDA = 0.232
KNN = 0.222
Bagged Tree = 0.233
Random Forest = 0.225
Neural Network = 0.222
SVM = 0.222

K-Nearest-Neighbor, Neural Networks, and Support Vector Machines were all equivalent in predicting the redlist status of a bird species. This is the same result as the 50/50 training/test data split. 



# Final Predictions of Unknown Status



# Conclusions

# Bibliography

IUCN 2020. The IUCN Red List of Threatened Species. Version 2020-1. https://www.iucnredlist.org. Downloaded on 19 March 2020.

Hamish Wilman, Jonathan Belmaker, Jennifer Simpson, Carolina de la Rosa, Marcelo M. Rivadeneira, Walter Jetz. 2014. EltonTraits 1.0: Species-level foraging attributes of the world's birds and mammals. Ecology 95:2027. http://dx.doi.org/10.1890/13-1917.1






