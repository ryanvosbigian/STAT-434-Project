---
title: "STAT 434 Project Modeling"
author: "Emma Barton and Ryan Vosbigian"
date: "5/21/2020"
output: html_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

```

Types of models to use:

Classification models only (could convert classes to numeric 1 thru 4, but makes our prediction undesirable, plus not equal jumps between classes)

  1. Logistic Regression (pairwise/one-versus-one and one-versus-all)?
  2. Linear Discriminant Analysis
  3. Quadratic Discriminant Analysis
  4. K-Nearest Neighbor
  5. Classification Tree
  6. Bagged Trees
  7. Random Forests
  8. Boosted Forests
  9. Neural Networks
  10. Support Vector Machines
  
Additional Considerations for Modeling

  1. PCA of all diet and foraging variables
    a. All diet variables are highly correlated, because they each sum up to 100. Thus, using PCA could really simplify the models considerably
    b. Additionally, if PCA is performed on diet variables then the diet variables should not be scaled because they already are by nature of the data
  2. Changing sensitivity of classifications so it is harder to be classified as Least Concern
    a. ROC Curves for each model
  
# Set Up

```{r load packages}

library(tidyverse)
library(class)

```

```{r set pathway}

## Local Pathways - copy/paste your local pathway to the github repository

# Emma
pathway = "/Users/emmabarton/Desktop/spring_2020/STAT434/project/"

# Ryan
#pathway = "~/GitHub/STAT-434---not-the-dodo-/"


```

```{r load data}

mammal_df = read.csv("cleaned_mammal_df.csv")
bird_df = read.csv("cleaned_bird_df_updated_5_29.csv")

```

# Preparing Data

## Transforming Variables

```{r changing variable types}

# Converting mammal activity variables to factors 
mammal_df$Activity.Nocturnal = as.factor(mammal_df$Activity.Nocturnal)
mammal_df$Activity.Crepuscular = as.factor(mammal_df$Activity.Crepuscular)
mammal_df$Activity.Diurnal = as.factor(mammal_df$Activity.Diurnal)

# Converting bird activity variables to factors 
bird_df$Nocturnal = as.factor(bird_df$Nocturnal)

```

```{r response variable transformations}

# Combine "Extinct" & "Extinct in the Wild" & "Critically Endangered" into "Endangered"
mammal_df$redlistCategory = as.character(car::recode(mammal_df$redlistCategory,recodes = "'Extinct'='Endangered';'Extinct in the Wild'='Endangered';'Critically Endangered'='Endangered'"))

bird_df$redlistCategory = as.character(car::recode(bird_df$redlistCategory,recodes = "'Extinct'='Endangered';'Extinct in the Wild'='Endangered';'Critically Endangered'='Endangered'"))

```

```{r explanatory variable transformations}

# Mammal Explanatory Variable Transformations
mammal_df = mammal_df %>% 
  mutate(
    log_bodymass = log(BodyMass.Value)
  )

# Bird Explanatory Variable Transformations 

```

## Making Training and Test Datasets

```{r separating data deficient observations}

# Moving data deficient mammals to different data set
data_deficient_mammals_df = mammal_df[mammal_df$redlistCategory == "Data Deficient",]
# Removing data deficient mammals
mammal_df = mammal_df[mammal_df$redlistCategory != "Data Deficient",]

# Moving data def birds to different dataset
data_deficient_birds_df = bird_df[bird_df$redlistCategory == "Data Deficient",]
# Removing data deficient birds
bird_df = bird_df[bird_df$redlistCategory != "Data Deficient",]

```

```{r creating test and training datasets}

# Creating indices for training sets
set.seed(10)
train_mammal = sample(1:nrow(mammal_df), size = round(nrow(mammal_df)/2))
train_bird = sample(1:nrow(bird_df), size = round(nrow(bird_df)/2))

# Creating training and test sets
mammal_train_df = mammal_df[train_mammal,]
mammal_test_df = mammal_df[-train_mammal,]

bird_train_df = bird_df[train_bird,]
bird_test_df = bird_df[-train_bird,]

```

## Testing PCA

Creating data frames with Principle Components as columns
```{r}

pcbirddiet = prcomp(bird_df[,c(12:21)],scale=FALSE)

pcbirdforage = prcomp(bird_df[,c(26:32)],scale=FALSE)

pcmammal = prcomp(mammal_df[,c(4:13)],scale = FALSE)

pcbird = prcomp(bird_df[,c(12:21,26:32)],scale=FALSE)

summary(pcmammal)


plot(cumsum(pcbirddiet$sdev^2/sum(pcbirddiet$sdev^2)), xlab="Principal  Component", ylab="Cumulative  Proportion  of Variance  Explained", ylim=c(0,1),type="b",main = "Bird Diet")

plot(cumsum(pcmammal$sdev^2/sum(pcmammal$sdev^2)), xlab="Principal  Component", ylab="Cumulative  Proportion  of Variance  Explained", ylim=c(0,1),type="b",main = "Mammal Diet")


plot(cumsum(pcbirdforage$sdev^2/sum(pcbirdforage$sdev^2)), xlab="Principal  Component", ylab="Cumulative  Proportion  of Variance  Explained", ylim=c(0,1),type="b",main = "Bird Foraging")

plot(cumsum(pcbird$sdev^2/sum(pcbird$sdev^2)), xlab="Principal  Component", ylab="Cumulative  Proportion  of Variance  Explained", ylim=c(0,1),type="b",main = "Bird Foraging and Diet")


colnames(pcbirddiet$x) = paste("Diet",colnames(pcbirddiet$x),sep = "")

colnames(pcmammal$x) = paste("Diet",colnames(pcmammal$x),sep = "")

colnames(pcbirdforage$x) = paste("For",colnames(pcbirdforage$x),sep = "")

colnames(pcbird$x) = paste("DietFor",colnames(pcbird$x),sep = "")

pc_bird_df = cbind(bird_df,
                   cbind(pcbirddiet$x,
                         cbind(pcbirdforage$x,pcbird$x)))

pc_mammal_df = cbind(mammal_df,pcmammal$x)


pc_mammal_train_df = pc_mammal_df[train_mammal,]
pc_mammal_test_df = pc_mammal_df[-train_mammal,]

pc_bird_train_df = pc_bird_df[train_bird,]
pc_bird_test_df = pc_bird_df[-train_bird,]

```

# 1: Logistic Regression
  
# 2: Linear Discriminant Analysis

Starting by using a bunch of variables and 
```{r}

library(MASS)

bird_lda1 = lda(redlistCategory ~ Diet.Inv + Diet.Vend + Diet.Vect + Diet.Vfish + Diet.Vunk + Diet.Scav + Diet.Fruit + Diet.Nect + Diet.Seed + Diet.PlantO + Diet.5Cat + ForStrat.watbelowsurf + ForStrat.wataroundsurf + ForStrat.aerial +  PelagicSpecialist + Nocturnal + BodyMass.Value, data=bird_train_df)

bird_lda1_pred=predict(bird_lda1, bird_test_df)

table(preds = bird_lda1_pred$class, truth = bird_test_df$redlistCategory)

mean(bird_lda_pred$class!=bird_test_df$redlistCategory)
#error rate 0.2279793
colnames(pc_bird_train_df)
#Using first 11 PCs for Diet and Foraging PCs, because that is where the elbow is in the graph above
bird_lda_pca1 = lda(redlistCategory ~ DietForPC1 + DietForPC2 + DietForPC3 + DietForPC4 + DietForPC5 + DietForPC6 + DietForPC7 + DietForPC8 + DietForPC9 + DietForPC10 +DietForPC11 + Diet.5Cat +  PelagicSpecialist + Nocturnal + scale(BodyMass.Value),data=pc_bird_train_df)

bird_lda_pca1_pred=predict(bird_lda_pca1, pc_bird_test_df)

table(preds = bird_lda_pca1_pred$class, truth = bird_test_df$redlistCategory)

mean(bird_lda_pca1_pred$class != bird_test_df$redlistCategory)
#error rate 0.2232124

```

# 3: Quadratic Discriminant Analysis

Getting errors because I have way to many predictors in model.
```{r}

bird_qda1 = qda(redlistCategory ~ Diet.Inv + Diet.Vend + Diet.Vect + Diet.Vfish + Diet.Vunk + Diet.Scav + Diet.Fruit + Diet.Nect + Diet.Seed + Diet.PlantO + ForStrat.watbelowsurf + ForStrat.wataroundsurf + ForStrat.aerial +  PelagicSpecialist + Nocturnal + scale(BodyMass.Value), data=bird_train_df)

bird_qda1_pred = predict(bird_qda1, bird_test_df)

table(preds = bird_qda1_pred$class,truth = bird_test_df$redlistCategory)

mean(bird_qda_pred$class != bird.test.df$redlistCategory)


bird_qda_pca1 = qda(redlistCategory ~ DietForPC1 + DietForPC2 + DietForPC3 + DietForPC4 + DietForPC5 + DietForPC6 + DietForPC7 + DietForPC8 + DietForPC9 + DietForPC10 +DietForPC11 +  PelagicSpecialist + Nocturnal + scale(BodyMass.Value),data=pc_bird_train_df)

bird_qda_pca1_pred = predict(bird_qda_pca1, pc_bird_test_df)

table(preds = bird_qda_pca1_pred$class, truth = bird_test_df$redlistCategory)

mean(bird_qda_pca1_pred$class != bird_test_df$redlistCategory)
#test error: 0.2945078

```

# 4: K-Nearest Neighbor

## Mammal K-Nearest Neighbor

### Format Variables
For some reason the knn function cannot deal with explanatory variables as factors so we'll have to recode categorical variables such as ForStrat.Value
```{r mammal change factors to numeric}

# Create separate dataframes for KNN
mammal_knn_train_df = mammal_train_df
mammal_knn_test_df = mammal_test_df

# Change factor variables to numeric
mammal_knn_train_df = mammal_knn_train_df %>% 
  mutate(
    Activity.Diurnal = as.numeric(Activity.Diurnal),
    Activity.Crepuscular = as.numeric(Activity.Crepuscular),
    Activity.Nocturnal = as.numeric(Activity.Nocturnal),
    
    for_strat_num = case_when(
      ForStrat.Value == "A" ~ 1,
      ForStrat.Value == "Ar" ~ 2,
      ForStrat.Value == "G" ~ 3,
      ForStrat.Value == "M" ~ 4,
      ForStrat.Value == "S" ~ 5
      ),
    for_strat_num = as.numeric(for_strat_num),
    
    pop_trend_num = case_when(
      populationTrend == "Decreasing" ~ 1,
      populationTrend == "Increasing" ~ 2,
      populationTrend == "Stable" ~ 3,
      populationTrend == "Unknown" ~ 4   
      ),
    pop_trend_num = as.numeric(pop_trend_num)
  )

mammal_knn_test_df = mammal_knn_test_df %>% 
  mutate(
    Activity.Diurnal = as.numeric(Activity.Diurnal),
    Activity.Crepuscular = as.numeric(Activity.Crepuscular),
    Activity.Nocturnal = as.numeric(Activity.Nocturnal),
    
    for_strat_num = case_when(
      ForStrat.Value == "A" ~ 1,
      ForStrat.Value == "Ar" ~ 2,
      ForStrat.Value == "G" ~ 3,
      ForStrat.Value == "M" ~ 4,
      ForStrat.Value == "S" ~ 5
      ),
    for_strat_num = as.numeric(for_strat_num),
    
    pop_trend_num = case_when(
      populationTrend == "Decreasing" ~ 1,
      populationTrend == "Increasing" ~ 2,
      populationTrend == "Stable" ~ 3,
      populationTrend == "Unknown" ~ 4   
      ),
    pop_trend_num = as.numeric(pop_trend_num)
  )

```

### Variable Selection
Explanatory Variables: Diet, Foraging Stratum, Activity, Body Mass, Population Trend
```{r mammal knn variable selection}

# KNN with all explanatory variables except foraging stratum
mammal_knn = knn(mammal_knn_train_df[,c(4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 
                                        20, 21, 41, 42, 43)],
                 mammal_knn_test_df[,c(4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 
                                       20, 21, 41, 42, 43)],
                 mammal_knn_train_df[,38], k=14)

```

```{r mammal prediction and error rate}

# Error Rate
mean(mammal_knn != mammal_knn_test_df$redlistCategory)

table(preds = mammal_knn, truth = mammal_knn_test_df$redlistCategory)

```

### Hyperparameter Tuning

```{r mammal k value selection}

test_errors = rep(0, 25)
for(i in 1:25){
  mammal_knn = knn(mammal_knn_train_df[,c(4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 
                                          19, 20, 21, 41, 42, 43)],
                 mammal_knn_test_df[,c(4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 
                                       20, 21, 41, 42, 43)],
                 mammal_knn_train_df[,38], k=i)
  test_errors[i] = mean(mammal_knn != mammal_knn_test_df$redlistCategory)
}

which.min(test_errors)

```


## Bird K-Nearest Neighbor

### Format Variables
```{r bird change factors to numeric}

bird_knn_train_df = bird_train_df
bird_knn_test_df = bird_test_df

```

### Variable Selection

### Hyperparameter Tuning

# 5: Classification Tree

# 6: Bagged Trees

# 7: Random Forests

# 8: Boosted Forests

# 9: Neural Networks

# 10: Support Vector Machines








