---
title: "STAT 434 Project Modeling"
author: "Emma Barton and Ryan Vosbigian"
date: "5/21/2020"
output: html_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

```



Types of models to use:

Classification models only (could convert classes to numeric 1 thru 4, but makes our prediction undesirable, plus not equal jumps between classes)

  1. Logistic Regression (pairwise/one-versus-one and one-versus-all)?
  2. Linear Discriminant Analysis
  3. Quadratic Discriminant Analysis
  4. K-Nearest Neighbor
  5. Classification Tree
  6. Bagged Trees
  7. Random Forests
  8. Boosted Forests
  9. Neural Networks
  10. Support Vector Machines
  
Additional Considerations for Modeling

  1. PCA of all diet and foraging variables
    a. All diet variables are highly correlated, because they each sum up to 100. Thus, using PCA could really simplify the models considerably
    b. Additionally, if PCA is performed on diet variables then the diet variables should not be scaled because they already are by nature of the data
  
# Set Up

```{r load packages}

library(tidyverse)
library(class)
library(tree)
library(randomForest)
library(MASS)
library(e1071)
library(nnet)

```

```{r set pathway}

## Local Pathways - copy/paste your local pathway to the github repository

# Emma
pathway = "/Users/emmabarton/Desktop/spring_2020/STAT434/project/"

# Ryan
#pathway = "~/GitHub/STAT-434---not-the-dodo-/"


```

```{r load data}

mammal_df = read.csv("cleaned_mammal_df.csv")
bird_df = read.csv("cleaned_bird_df_updated_5_29.csv")

```

```{r chopping off extra rows}

nrow(bird_df)
bird_df = bird_df[1:9640,]

```

# Preparing Data

## Transforming Variables

```{r changing variable types}

# Converting mammal activity variables to factors 
mammal_df$Activity.Nocturnal = as.factor(mammal_df$Activity.Nocturnal)
mammal_df$Activity.Crepuscular = as.factor(mammal_df$Activity.Crepuscular)
mammal_df$Activity.Diurnal = as.factor(mammal_df$Activity.Diurnal)
mammal_df$redlistCategory = as.factor(mammal_df$redlistCategory)

# Converting bird activity variables to factors 
bird_df$Nocturnal = as.factor(bird_df$Nocturnal)
bird_df$redlistCategory = as.factor(bird_df$redlistCategory)

```

```{r response variable transformations}

# Combine "Extinct" & "Extinct in the Wild" & "Critically Endangered" into "Endangered"
mammal_df$redlistCategory = as.character(car::recode(mammal_df$redlistCategory,recodes = "'Extinct'='Endangered';'Extinct in the Wild'='Endangered';'Critically Endangered'='Endangered'"))

bird_df$redlistCategory = as.character(car::recode(bird_df$redlistCategory,recodes = "'Extinct'='Endangered';'Extinct in the Wild'='Endangered';'Critically Endangered'='Endangered'"))

```

```{r explanatory variable transformations}

# Mammal Explanatory Variable Transformations
mammal_df = mammal_df %>% 
  mutate(
    log_bodymass = log(BodyMass.Value)
  )


# Bird Explanatory Variable Transformations 

bird_df = bird_df %>% 
  mutate(
    log_bodymass = log(BodyMass.Value)
  )
```

## Adding PCA of Diet and Foraging

Creating data frames with Principle Components as columns
```{r}

pcbirddiet = prcomp(bird_df[,c(12:21)],scale=FALSE)

pcbirdforage = prcomp(bird_df[,c(26:32)],scale=FALSE)

pcmammal = prcomp(mammal_df[,c(4:13)],scale = FALSE)

pcbird = prcomp(bird_df[,c(12:21,26:32)],scale=FALSE)

summary(pcmammal)


plot(cumsum(pcbirddiet$sdev^2/sum(pcbirddiet$sdev^2)), xlab="Principal  Component", ylab="Cumulative  Proportion  of Variance  Explained", ylim=c(0,1),type="b",main = "Bird Diet")

plot(cumsum(pcmammal$sdev^2/sum(pcmammal$sdev^2)), xlab="Principal  Component", ylab="Cumulative  Proportion  of Variance  Explained", ylim=c(0,1),type="b",main = "Mammal Diet")


plot(cumsum(pcbirdforage$sdev^2/sum(pcbirdforage$sdev^2)), xlab="Principal  Component", ylab="Cumulative  Proportion  of Variance  Explained", ylim=c(0,1),type="b",main = "Bird Foraging")

plot(cumsum(pcbird$sdev^2/sum(pcbird$sdev^2)), xlab="Principal  Component", ylab="Cumulative  Proportion  of Variance  Explained", ylim=c(0,1),type="b",main = "Bird Foraging and Diet")


colnames(pcbirddiet$x) = paste("Diet",colnames(pcbirddiet$x),sep = "")

colnames(pcmammal$x) = paste("Diet",colnames(pcmammal$x),sep = "")

colnames(pcbirdforage$x) = paste("For",colnames(pcbirdforage$x),sep = "")

colnames(pcbird$x) = paste("DietFor",colnames(pcbird$x),sep = "")

bird_df = cbind(bird_df,
                   cbind(pcbirddiet$x,
                         cbind(pcbirdforage$x,pcbird$x)))

mammal_df = cbind(mammal_df,pcmammal$x)

remove(pcbird,pcbirddiet,pcbirdforage,pcmammal)

```

## Making Training and Test Datasets

```{r separating data deficient observations}

# Moving data deficient mammals to different data set
data_deficient_mammals_df = mammal_df[mammal_df$redlistCategory == "Data Deficient",]
# Removing data deficient mammals
mammal_df = mammal_df[mammal_df$redlistCategory != "Data Deficient",]

# Moving data def birds to different dataset
data_deficient_birds_df = bird_df[bird_df$redlistCategory == "Data Deficient",]
# Removing data deficient birds
bird_df = bird_df[bird_df$redlistCategory != "Data Deficient",]

```

```{r creating test and training datasets}

# Creating indices for training sets
set.seed(10)
train_mammal = sample(1:nrow(mammal_df), size = round(nrow(mammal_df)/2))
train_bird = sample(1:nrow(bird_df), size = round(nrow(bird_df)/2))

# Creating training and test sets
mammal_train_df = mammal_df[train_mammal,]
mammal_test_df = mammal_df[-train_mammal,]

bird_train_df = bird_df[train_bird,]
bird_test_df = bird_df[-train_bird,]

```

# 1: Logistic Regression
  
## Mammal Logistic Regression

### Format Variables

```{r}

# Create separate logistic regression dataframe
mammals_log_train_df = mammal_train_df
mammals_log_test_df = mammal_test_df

# Change Response to Binary
mammals_log_train_df = mammals_log_train_df %>% 
  mutate(
    redlistCategory = case_when(
      redlistCategory == "Endangered" ~ 1,
      redlistCategory == "Near Threatened" ~ 1,
      redlistCategory == "Vulnerable" ~ 1,
      TRUE ~ 0
    )
  )

mammals_log_test_df = mammals_log_test_df %>% 
  mutate(
    redlistCategory = case_when(
      redlistCategory == "Endangered" ~ 1,
      redlistCategory == "Near Threatened" ~ 1,
      redlistCategory == "Vulnerable" ~ 1,
      TRUE ~ 0
    )
  )

```

### Variable Selection

```{r}

mammal_log_variables = list(c(38,4, 5, 6, 7, 8, 9, 10, 11, 12, 13), #all diet variables
                            c(38,7, 9, 10, 11, 12, 13),                  #selected diet variables
                            c(38,41),                               #log body mass
                            c(38,19, 20, 21, 41),                   #activity and body mass
                            c(38,4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 20, 21), #all diet and activity variables
                            c(38,4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 41),         #all diet and body mass
                            c(38,41, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 20, 21), #all diet and activity and body mass
                            c(38,7, 9, 10, 11, 12, 13, 41), #selected activity variables and body mass
                            c(38,7, 9, 10, 11, 12, 13, 19, 20, 21), #selected diet and activity
                            c(38,7, 9, 10, 11, 12, 13, 19, 20, 21, 41), #selected diet, activity and body mass
                            c(38,42, 43, 44, 45, 46, 47, 48), # 7 PC for diet
                            c(38,42, 43, 44, 45, 46, 47, 48, 41), # PCA for diet and diet
                            c(38,42, 43, 44, 45, 46, 47, 48, 19, 20, 21), # PCA for diet and activity
                            c(38,42, 43, 44, 45, 46, 47, 48, 19, 20, 21, 41), # PCA for diet, activity, and body mass
                            c(38,7, 9, 10, 11, 12, 13, 16),     #selected diet variables and foraging
                            c(38,7, 9, 10, 11, 12, 13, 41, 16), #selected activity variables and body mass and foraging
                            c(38, 16, 19, 20, 21), # activity and foraging
                            c(38, 16, 42, 43, 44, 45, 46, 47, 48, 41),   # PCA for diet, and body mass and foraging
                            c(38, 16, 42, 43, 44, 45, 46, 47, 48, 19, 20, 21, 41), #PCAdiet, and activity, body mass, and foraging
                            c(38,7, 9, 10, 11, 12, 13, 19, 20, 21, 41, 16)#selected diet, activity and body mass and foraging
                        
                            )  
test_errors = rep(0, length(mammal_log_variables))

for(i in 1:length(mammal_log_variables)){
  var = mammal_log_variables[[i]]
  mammal_log = glm(redlistCategory ~ .,
                   data = mammals_log_train_df[,var])
  log_prob = predict(mammal_log, newdata=mammals_log_test_df[,var], type = "response")
  log_pred = rep(0, 2146)
  log_pred[log_prob > 0.5] = 1
  test_errors[i] = mean(log_pred != mammals_log_test_df$redlistCategory)
}

which.min(test_errors)
mammal_log_variables[[which.min(test_errors)]]

# Best Variables: Selected diet variables, bodymass, and foraging

```

### Best Model

```{r}

var = mammal_log_variables[[16]]
mammal_log = glm(redlistCategory ~ .,
                   data = mammals_log_train_df[,var])
log_prob = predict(mammal_log, newdata=mammals_log_test_df[,var], type = "response")
log_pred = rep(0, 2146)
log_pred[log_prob > 0.5] = 1
mean(log_pred != mammals_log_test_df$redlistCategory)

# Error rate = 0.288

```

## Bird Logistic Regression
  
### Format Variables

```{r}

# Create separate logistic regression dataframe
bird_log_train_df = bird_train_df
bird_log_test_df = bird_test_df

# Change Response to Binary
bird_log_train_df = bird_log_train_df %>% 
  mutate(
    redlistCategory = case_when(
      redlistCategory == "Endangered" ~ 1,
      redlistCategory == "Near Threatened" ~ 1,
      redlistCategory == "Vulnerable" ~ 1,
      TRUE ~ 0
    )
  )

bird_log_test_df = bird_log_test_df %>% 
  mutate(
    redlistCategory = case_when(
      redlistCategory == "Endangered" ~ 1,
      redlistCategory == "Near Threatened" ~ 1,
      redlistCategory == "Vulnerable" ~ 1,
      TRUE ~ 0
    )
  )

```

### Variable Selection

```{r}
# Having trouble with bird logistic regression
bird_log_variables = list(#c(54, 12:21), # all diet variables
                          #c(54, 37,57), # activity and body mass
                          #c(54, 12:21, 37), # all diet and activity variables
                          #c(54, 12:21, 57), # all diet and body mass
                          #c(54, 12:21, 37, 57), # all diet and activity and body mass
                          c(54, 26:33), # foraging variables
                          #c(54, 26:33, 12:21), # diet and foraging
                          #c(54, 26:33, 57), # foraging and body mass
                          #c(54, 26:33, 12:21, 37, 57), 
                          # foraging, body mass, activity, and diet
                          #c(54, 75:91), # PCA for diet and foraing together
                          c(54, 75:91, 57), 
                          # PCA for diet and foraging together and body mass
                          c(54, 75:91, 57, 37)
                          # PCA for diet + foraging, activity, and body mass
                        )
test_errors = rep(0, length(bird_log_variables))

for(i in 1:length(bird_log_variables)){
  var = bird_log_variables[[i]]
  print(var)
  bird_log = glm(redlistCategory ~ .,
                   data = bird_log_train_df[,var])
  log_prob = predict(bird_log, newdata=bird_log_test_df[,var], type = "response")
  log_pred = rep(0, 2146)
  log_pred[log_prob > 0.5] = 1
  test_errors[i] = mean(log_pred != bird_log_test_df$redlistCategory)
}

which.min(test_errors)
bird_log_variables[[which.min(test_errors)]]

```

### Best Model

# 2: Linear Discriminant Analysis

## Mammals

```{r}

mam_lda1 = lda(redlistCategory ~ Diet.Vfish + Diet.Vend + Diet.Scav + Diet.Seed + Diet.Inv + Diet.Fruit + Diet.Nect +  + Diet.PlantO + ForStrat.Value + Activity.Nocturnal + Activity.Crepuscular +  Activity.Diurnal + log_bodymass, data=mammal_train_df)

mam_lda1_pred=predict(mam_lda1, mammal_test_df)

table(preds = mam_lda1_pred$class, truth = mammal_test_df$redlistCategory)

mean(mam_lda1_pred$class!=mammal_test_df$redlistCategory)
#error rate 0.3080149
mam_lda1

```

```{r}

mam_lda1 = lda(redlistCategory ~ Diet.Vfish + Diet.Vend + Diet.Scav + Diet.Seed + Diet.Inv + Diet.Fruit + Diet.Nect +  + Diet.PlantO + ForStrat.Value + Activity.Nocturnal + Activity.Crepuscular +  Activity.Diurnal + log_bodymass, data=mammal_train_df)

mam_lda1_pred=predict(mam_lda1, mammal_test_df)

table(preds = mam_lda1_pred$class, truth = mammal_test_df$redlistCategory)

mean(mam_lda1_pred$class!=mammal_test_df$redlistCategory)
#error rate 0.3080149
```


### Variable Selection

```{r}
mammal_lda_variables = list(c(38,7, 9, 10, 11, 12, 13),                  #selected diet variables
                            c(38,19, 20, 21, 41),                   #activity and body mass
                            c(38,41, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 20, 21), #all diet and activity and body mass
                            c(38,7, 9, 10, 11, 12, 13, 41), #selected activity variables and body mass
                            c(38,7, 9, 10, 11, 12, 13, 19, 20, 21), #selected diet and activity
                            c(38,7, 9, 10, 11, 12, 13, 19, 20, 21, 41), #selected diet, activity and body mass
                            c(38,42, 43, 44, 45, 46, 47, 48, 41), # PCA for diet and body mass
                            c(38,42, 43, 44, 45, 46, 47, 48, 19, 20, 21), # PCA for diet and activity
                            c(38,42, 43, 44, 45, 46, 47, 48, 19, 20, 21, 41), # PCA for diet, activity, and body mass
                            c(38,7, 9, 10, 11, 12, 13, 16),     #selected diet variables and foraging
                            c(38,7, 9, 10, 11, 12, 13, 41, 16), #selected activity variables and body mass and foraging
                            c(38, 16, 19, 20, 21), # activity and foraging
                            c(38, 16, 42, 43, 44, 45, 46, 47, 48, 41),   # PCA for diet, and body mass and foraging
                            c(38, 16, 42, 43, 44, 45, 46, 47, 48, 19, 20, 21, 41), #PCAdiet, and activity, body mass, and foraging
                            c(38,7, 9, 10, 11, 12, 13, 19, 20, 21, 41, 16)#selected diet, activity and body mass and foraging
                        
                            )  
test_errors = rep(0, length(mammal_lda_variables))

mammal_train_df[,mammal_lda_variables[[1]]]

for(i in 1:length(mammal_lda_variables)){
  var = mammal_lda_variables[[i]]
  mammal_lda = lda(redlistCategory ~ .,
                   data = mammal_train_df[,var])
  lda_pred = predict(mammal_lda,newdata=mammal_test_df[,var])
  test_errors[i] = mean(lda_pred$class != mammal_test_df$redlistCategory)
}

which.min(test_errors)
mammal_lda_variables[[which.min(test_errors)]]



```
### Best Model

```{r}

mammal_lda = lda(redlistCategory ~ .,
                   data = mammal_train_df[,mammal_lda_variables[[19]]])
lda_pred = predict(mammal_lda,newdata=mammal_test_df[,mammal_lda_variables[[19]]])
mean(lda_pred$class != mammal_test_df$redlistCategory)
table(pred=lda_pred$class,truth=mammal_test_df$redlistCategory)

#test error 0.3089469

colnames(mammal_train_df)[mammal_lda_variables[[19]]]
```

## Birds

```{r}

library(MASS)
library(pROC)

bird_lda1 = lda(redlistCategory ~ Diet.Inv + Diet.Vend + Diet.Vect + Diet.Vfish + Diet.Vunk + Diet.Scav + Diet.Fruit + Diet.Nect + Diet.Seed + Diet.PlantO + ForStrat.watbelowsurf + ForStrat.wataroundsurf + ForStrat.aerial +  PelagicSpecialist + Nocturnal + BodyMass.Value, data=bird_train_df)

bird_lda1_pred=predict(bird_lda1, bird_test_df)

table(preds = bird_lda1_pred$class, truth = bird_test_df$redlistCategory)

mean(bird_lda1_pred$class!=bird_test_df$redlistCategory)
#error rate 0.2315066


#Using first 11 PCs for Diet and Foraging PCs, because that is where the elbow is in the graph above
bird_lda_pca1 = lda(redlistCategory ~ DietForPC1 + DietForPC2 + DietForPC3 + DietForPC4 + DietForPC5 + DietForPC6 + DietForPC7 + DietForPC8 + DietForPC9 + DietForPC10 +DietForPC11 +  PelagicSpecialist + Nocturnal + scale(BodyMass.Value),data=bird_train_df)

bird_lda_pca1_pred=predict(bird_lda_pca1, bird_test_df)

table(preds = bird_lda_pca1_pred$class, truth = bird_test_df$redlistCategory)

mean(bird_lda_pca1_pred$class != bird_test_df$redlistCategory)
#error rate 0.2287977
colnames(bird_test_df)
```

### Variable Selection

```{r}

bird_lda_variables = list(c(54, 12:21), #all diet variables
                            c(54,91),                               #log body mass
                            c(54,37,91),                   #activity and body mass
                            c(54,12:21, 37), #all diet and activity variables
                            c(54,12:21, 91),         #all diet and body mass
                            c(54,12:21, 37, 91), #all diet and activity and body mass
                            c(54,26:33), # foraging variables
                            c(54,26:33, 12:21), # diet and foraging
                            c(54,26:33,91), #foraging and body mass
                            c(54,26:33, 12:21, 37, 91), # foraging, body mass, activity, and diet
                            c(54,109:119), # PCA for diet and foraing together
                            c(54,109:119, 91), # PCA for diet and foraging together and body mass
                            c(54,109:119, 91, 37) # PCA for diet + foraging, activity, and body mass
                            )
test_errors = rep(0, length(bird_lda_variables))



for(i in 1:length(bird_lda_variables)){
  var = bird_lda_variables[[i]]
  bird_lda = lda(redlistCategory ~ .,
                   data = bird_train_df[,var])
  lda_pred = predict(bird_lda,newdata=bird_test_df[,var])
  test_errors[i] = mean(lda_pred$class != bird_test_df$redlistCategory)
}

which.min(test_errors)
bird_lda_variables[[which.min(test_errors)]]
```


### Best Model

```{r}
bird_lda = lda(redlistCategory ~ .,
                   data = bird_train_df[,bird_lda_variables[[7]]])
lda_pred = predict(bird_lda,newdata=bird_test_df[,bird_lda_variables[[7]]])
mean(lda_pred$class != bird_test_df$redlistCategory)
table(pred=lda_pred$class,truth=bird_test_df$redlistCategory)

#test error 0.227339

colnames(bird_train_df)[mammal_lda_variables[[7]]]
```
This is the worst possible model.


# 3: Quadratic Discriminant Analysis

## Mammals

### Variable Selection

```{r}

# using less variables to avoid rank deficiency, just removing some that have collinearity
mammal_qda_variables = list(c(38,4, 5, 6, 7, 8, 9, 10, 11,13), #all diet variables
                            c(38,7, 9, 10, 11, 13),                  #selected diet variables
                            c(38,41),                               #log body mass
                            c(38,19, 20, 21, 41),                   #activity and body mass
                            c(38,4, 5, 6, 7, 8, 9, 10, 11, 19, 20), #all diet and activity variables
                            c(38,4, 5, 6, 7, 8, 9, 10, 11, 13, 41),         #all diet and body mass
                            c(38,41, 4, 5, 6, 7, 8, 9, 10, 11, 13, 19, 20, 21), #all diet and activity and body mass
                            c(38,7, 9, 10, 11, 13, 41), #selected activity variables and body mass
                            c(38,7, 9, 10, 11, 13, 19, 20, 21), #selected diet and activity
                            c(38,7, 9, 10, 11, 13, 19, 20, 21, 41), #selected diet, activity and body mass
                            c(38,42, 43, 44, 45, 46, 47, 48), # 7 PC for diet
                            c(38,42, 43, 44, 45, 46, 47, 48, 41), # PCA for diet and diet
                            c(38,42, 43, 44, 45, 46, 47, 48, 19, 20, 21), # PCA for diet and activity
                            c(38,42, 43, 44, 45, 46, 47, 48, 19, 20, 21, 41), # PCA for diet, activity, and body mass
                            c(38,7, 9, 10, 11, 12, 13, 16),     #selected diet variables and foraging
                            c(38,7, 9, 10, 11, 12, 13, 41, 16), #selected activity variables and body mass and foraging
                            c(38, 16, 19, 20, 21), # activity and foraging
                            c(38, 16, 42, 43, 44, 45, 46, 47, 48, 41),   # PCA for diet, and body mass and foraging
                            c(38, 16, 42, 43, 44, 45, 46, 47, 48, 19, 20, 21, 41), #PCAdiet, and activity, body mass, and foraging
                            c(38,7, 9, 10, 11, 12, 13, 19, 20, 21, 41, 16)#selected diet, activity and body mass and foraging
                            )  
test_errors = rep(0, length(mammal_lda_variables))



for(i in 1:length(mammal_qda_variables)){
  var = mammal_qda_variables[[i]]
  mammal_qda = qda(redlistCategory ~ .,
                   data = mammal_train_df[,var])
  qda_pred = predict(mammal_qda,newdata=mammal_test_df[,var])
  test_errors[i] = mean(qda_pred$class != mammal_test_df$redlistCategory)
}

which.min(test_errors)
mammal_qda_variables[[which.min(test_errors)]]
```

### Best Model

```{r}
mammal_qda = qda(redlistCategory ~ .,
                   data = mammal_train_df[,mammal_qda_variables[[3]]])
qda_pred = predict(mammal_qda,newdata=mammal_test_df[,mammal_qda_variables[[3]]])
mean(qda_pred$class != mammal_test_df$redlistCategory)
table(pred=qda_pred$class,truth=mammal_test_df$redlistCategory)

#test error 0.3289842

colnames(mammal_train_df)[mammal_qda_variables[[3]]]
```


## Birds

### Variable Selection

```{r}
#removing first diet and foraging variables to avoid rank deficiency
bird_qda_variables = list(c(54, 13:21), #all diet variables
                            c(54,91),                               #log body mass
                            c(54,37,91),                   #activity and body mass
                            c(54,13:21, 37), #all diet and activity variables
                            c(54,13:21, 91),         #all diet and body mass
                            c(54,13:21, 37, 91), #all diet and activity and body mass
                            c(54,27:33), # foraging variables
                            c(54,27:33, 13:21), # diet and foraging
                            c(54,27:33,91), #foraging and body mass
                            c(54,27:33, 13:21, 37, 91), # foraging, body mass, activity, and diet
                            c(54,109:119), # PCA for diet and foraing together
                            c(54,109:119, 91), # PCA for diet and foraging together and body mass
                            c(54,109:119, 91, 37) # PCA for diet + foraging, activity, and body mass
                            )
test_errors = rep(0, length(bird_qda_variables))



for(i in 1:length(bird_qda_variables)){
  var = bird_qda_variables[[i]]
  bird_qda = qda(redlistCategory ~ .,
                   data = bird_train_df[,var])
  qda_pred = predict(bird_qda,newdata=bird_test_df[,var])
  test_errors[i] = mean(qda_pred$class != bird_test_df$redlistCategory)
}

which.min(test_errors)
bird_qda_variables[[which.min(test_errors)]]

```


### Best Model

```{r}
bird_qda = qda(redlistCategory ~ .,
                   data = bird_train_df[,bird_qda_variables[[2]]])
qda_pred = predict(bird_qda,newdata=bird_test_df[,bird_qda_variables[[2]]])
mean(qda_pred$class != bird_test_df$redlistCategory)
table(pred=qda_pred$class,truth=bird_test_df$redlistCategory)

#test error 0.2279642

colnames(bird_train_df)[bird_qda_variables[[2]]]
```

# 4: K-Nearest Neighbor

## Mammal K-Nearest Neighbor

### Format Variables
For some reason the knn function cannot deal with explanatory variables as factors so we'll have to recode categorical variables such as ForStrat.Value
```{r mammal change factors to numeric}

# Create separate dataframes for KNN
mammal_knn_train_df = mammal_train_df
mammal_knn_test_df = mammal_test_df

# Change factor variables to numeric
mammal_knn_train_df = mammal_knn_train_df %>% 
  mutate(
    Activity.Diurnal = as.numeric(Activity.Diurnal),
    Activity.Crepuscular = as.numeric(Activity.Crepuscular),
    Activity.Nocturnal = as.numeric(Activity.Nocturnal),
    
    for_strat_num = case_when(
      ForStrat.Value == "A" ~ 1,
      ForStrat.Value == "Ar" ~ 2,
      ForStrat.Value == "G" ~ 3,
      ForStrat.Value == "M" ~ 4,
      ForStrat.Value == "S" ~ 5
      ),
    for_strat_num = as.numeric(for_strat_num)
  )

mammal_knn_test_df = mammal_knn_test_df %>% 
  mutate(
    Activity.Diurnal = as.numeric(Activity.Diurnal),
    Activity.Crepuscular = as.numeric(Activity.Crepuscular),
    Activity.Nocturnal = as.numeric(Activity.Nocturnal),
    
    for_strat_num = case_when(
      ForStrat.Value == "A" ~ 1,
      ForStrat.Value == "Ar" ~ 2,
      ForStrat.Value == "G" ~ 3,
      ForStrat.Value == "M" ~ 4,
      ForStrat.Value == "S" ~ 5
      ),
    for_strat_num = as.numeric(for_strat_num)
  )

```

### Variable Selection
Explanatory Variables: Diet, Foraging Stratum, Activity, Body Mass. It appears that you cannot make single explanatory variable KNN models.
```{r mammal knn variable selection}

mammal_knn_variables = list(c(4, 5, 6, 7, 8, 9, 10, 11, 12, 13), # all diet variables
                            c(7, 9, 10, 11, 12, 13), # selected diet variables
                            c(19, 20, 21, 41), # activity and body mass
                            c(4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 20, 21), 
                            # all diet and activity variables
                            c(4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 41),        
                            # all diet and body mass
                            c(41, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 20, 21), 
                            # all diet and activity and body mass
                            c(7, 9, 10, 11, 12, 13, 41),
                            # selected activity variables and body mass
                            c(7, 9, 10, 11, 12, 13, 19, 20, 21), 
                            # selected diet and activity
                            c(7, 9, 10, 11, 12, 13, 19, 20, 21, 41), 
                            # selected diet, activity and body mass
                            c(42, 43, 44, 45, 46, 47, 48), # 7 PCA for diet
                            c(42, 43, 44, 45, 46, 47, 48, 41), 
                            # PCA for diet and bodymass
                            c(42, 43, 44, 45, 46, 47, 48, 19, 20, 21), 
                            # PCA for diet and activity
                            c(42, 43, 44, 45, 46, 47, 48, 19, 20, 21, 41), 
                            # PCA for diet, activity, and body mass
                            c(7, 9, 10, 11, 12, 13, 52),     
                            # selected diet variables and foraging
                            c(7, 9, 10, 11, 12, 13, 41, 52), 
                            # selected activity variables and body mass and foraging
                            c(52, 19, 20, 21), # activity and foraging
                            c(52, 42, 43, 44, 45, 46, 47, 48, 41),   
                            # PCA for diet, and body mass and foraging
                            c(52, 42, 43, 44, 45, 46, 47, 48, 19, 20, 21, 41), 
                            # PCA diet, and activity, body mass, and foraging
                            c(7, 9, 10, 11, 12, 13, 19, 20, 21, 41, 52)
                            # selected diet, activity and body mass and foraging
                            )
test_errors = rep(0, length(mammal_knn_variables))

for(i in 1:length(mammal_knn_variables)){
  var = mammal_knn_variables[[i]]
  mammal_knn = knn(mammal_knn_train_df[,var],
                 mammal_knn_test_df[,var],
                 mammal_knn_train_df[,38], k=14)
  test_errors[i] = mean(mammal_knn != mammal_knn_test_df$redlistCategory)
}

which.min(test_errors)
mammal_knn_variables[[which.min(test_errors)]]

# Best Variables: Selected Diet + Activity Variables 

```

```{r mammal prediction and error rate}

mean(mammal_knn != mammal_knn_test_df$redlistCategory)
table(preds = mammal_knn, truth = mammal_knn_test_df$redlistCategory)

# Error rate = 0.311

```

### Hyperparameter Tuning

```{r mammal k value selection}

test_errors = rep(0, 25)
for(i in 1:25){
  mammal_knn = knn(mammal_knn_train_df[,c(7, 9, 10, 11, 12, 13, 19, 20, 21)],
                 mammal_knn_test_df[,c(7, 9, 10, 11, 12, 13, 19, 20, 21)],
                 mammal_knn_train_df[,38], k=i)
  test_errors[i] = mean(mammal_knn != mammal_knn_test_df$redlistCategory)
}

which.min(test_errors)

```

### Best Model

```{r mammal best knn model}

mammal_knn = knn(mammal_knn_train_df[,c(7, 9, 10, 11, 12, 13, 19, 20, 21)],
                 mammal_knn_test_df[,c(7, 9, 10, 11, 12, 13, 19, 20, 21)],
                 mammal_knn_train_df[,38], k=14)
mean(mammal_knn != mammal_knn_test_df$redlistCategory)

# Error rate = 0.305

```

## Bird K-Nearest Neighbor

### Format Variables

```{r bird change factors to numeric}

bird_knn_train_df = bird_train_df
bird_knn_test_df = bird_test_df

# Change factor variables to numeric
bird_knn_train_df = bird_knn_train_df %>% 
  mutate(
    Nocturnal = as.numeric(Nocturnal)
  )

bird_knn_test_df = bird_knn_test_df %>% 
  mutate(
    Nocturnal = as.numeric(Nocturnal)
  )

```

### Variable Selection
Explanatory variables: Body Mass, Diet, Activity, Foraging
```{r bird knn variable selection}

# Commented out variable groups had too many ties
bird_knn_variables = list(#c(12:21), # all diet variables
                          c(37,57), # activity and body mass
                          #c(12:21, 37), # all diet and activity variables
                          c(12:21, 57), # all diet and body mass
                          c(12:21, 37, 57), # all diet and activity and body mass
                          c(26:33), # foraging variables
                          c(26:33, 12:21), # diet and foraging
                          c(26:33, 57), # foraging and body mass
                          c(26:33, 12:21, 37, 57), 
                          # foraging, body mass, activity, and diet
                          c(75:91), # PCA for diet and foraing together
                          c(75:91, 57), 
                          # PCA for diet and foraging together and body mass
                          c(75:91, 57, 37)
                          # PCA for diet + foraging, activity, and body mass
                        )
test_errors = rep(0, length(bird_knn_variables))

for(i in 1:length(bird_knn_variables)){
  var = bird_knn_variables[[i]]
  bird_knn = knn(bird_knn_train_df[,var],
                 bird_knn_test_df[,var],
                 bird_knn_train_df[,54], k=14)
  test_errors[i] = mean(bird_knn != bird_knn_test_df$redlistCategory)
}

which.min(test_errors)
bird_knn_variables[[which.min(test_errors)]]

# Best Variables: Foraging variables

```

```{r bird prediction and error rate}

mean(bird_knn != bird_knn_test_df$redlistCategory)
table(preds = bird_knn, truth = bird_knn_test_df$redlistCategory)

# Error rate = 0.223

```

### Hyperparameter Tuning

```{r bird k value selection}

test_errors = rep(0, 25)
for(i in 1:25){
  bird_knn = knn(bird_knn_train_df[,c(26:33)],
                 bird_knn_test_df[,c(26:33)],
                 bird_knn_train_df[,54], k=i)
  test_errors[i] = mean(bird_knn != bird_knn_test_df$redlistCategory)
}

which.min(test_errors)

```

### Best Model

```{r mammal best knn model}

bird_knn = knn(bird_knn_train_df[,c(26:33)],
                 bird_knn_test_df[,c(26:33)],
                 bird_knn_train_df[,54], k=12)
mean(bird_knn != bird_knn_test_df$redlistCategory)

# Error rate = 0.222

```

# 5: Classification Tree

## Mammal Classification Tree

```{r mammal change variable types}

mammal_train_df$redlistCategory = as.factor(mammal_train_df$redlistCategory)
mammal_test_df$redlistCategory = as.factor(mammal_test_df$redlistCategory)

```

```{r mammal class tree}

mammal_tree = tree(redlistCategory ~ log_bodymass + ForStrat.Value + 
                   Activity.Crepuscular + Activity.Diurnal + Activity.Nocturnal + 
                   Diet.Inv + Diet.Vend + Diet.Vect + Diet.Vfish + Diet.Vunk + 
                   Diet.Scav + Diet.Fruit + Diet.PlantO, 
                   mammal_train_df)

```

```{r mammal tree assessment}

summary(mammal_tree)

plot(mammal_tree)
text(mammal_tree, pretty = 0)

```


# 6: Bagged Trees

## Mammal Bagged Trees

### Variable Selection

```{r}
#Using variables selected for LDA
test_errors = rep(0, length(mammal_lda_variables))



for(i in 1:length(mammal_lda_variables)){
  var = mammal_lda_variables[[i]]
  mammal_lda = randomForest(as.factor(redlistCategory) ~ .,
                   data = mammal_train_df[,var],
                   mtry = (length(var)-1))
  bag_pred = predict(mammal_lda,newdata=mammal_test_df[,var])
  test_errors[i] = mean(bag_pred != mammal_test_df$redlistCategory)
}

which.min(test_errors)
mammal_lda_variables[[which.min(test_errors)]]


```

### Best Model

```{r}
var = mammal_lda_variables[[2]]
mammal_lda = randomForest(as.factor(redlistCategory) ~ .,
                   data = mammal_train_df[,var],
                   mtry = (length(var)-1))
bag_pred = predict(mammal_lda,newdata=mammal_test_df[,var])
mean(bag_pred != mammal_test_df$redlistCategory)
table(bag_pred, mammal_test_df$redlistCategory)

colnames(mammal_train_df)[mammal_lda_variables[[2]]]

# test error 0.3187325
```

## Bird Bagged Trees

### Variable Selection

```{r}
#Using variables selected for LDA
test_errors = rep(0, length(bird_lda_variables))



for(i in 1:length(bird_lda_variables)){
  var = bird_lda_variables[[i]]
  bird_lda = randomForest(as.factor(redlistCategory) ~ .,
                   data = bird_train_df[,var],
                   mtry = (length(var)-1))
  bag_pred = predict(bird_lda,newdata=bird_test_df[,var])
  test_errors[i] = mean(bag_pred != bird_test_df$redlistCategory)
}

which.min(test_errors)
bird_lda_variables[[which.min(test_errors)]]
```

### Best Model

```{r}
var = bird_lda_variables[[7]]
bird_lda = randomForest(as.factor(redlistCategory) ~ .,
                   data = bird_train_df[,var],
                   mtry = (length(var)-1))
bag_pred = predict(bird_lda,newdata=bird_test_df[,var])
mean(bag_pred != bird_test_df$redlistCategory)
table(bag_pred, bird_test_df$redlistCategory)

colnames(bird_train_df)[bird_lda_variables[[7]]]

#test error 0.2358825

```

# 7: Random Forests

## Mammal Random Forests

### Variable Selection

```{r}
#Using variables selected for LDA
test_errors = rep(0, length(mammal_lda_variables))


set.seed(10)
for(i in 1:length(mammal_lda_variables)){
  var = mammal_lda_variables[[i]]
  mammal_lda = randomForest(as.factor(redlistCategory) ~ .,
                   data = mammal_train_df[,var],
                   mtry = round(sqrt(length(var)-1))
                   )
  bag_pred = predict(mammal_lda,newdata=mammal_test_df[,var])
  test_errors[i] = mean(bag_pred != mammal_test_df$redlistCategory)
}

which.min(test_errors)
mammal_lda_variables[[which.min(test_errors)]]


```

### Best Model

```{r}
set.seed(10)
var = mammal_lda_variables[[10]]
mammal_lda = randomForest(as.factor(redlistCategory) ~ .,
                   data = mammal_train_df[,var],
                   mtry = round(sqrt(length(var)-1))
                   )
bag_pred = predict(mammal_lda,newdata=mammal_test_df[,var])
mean(bag_pred != mammal_test_df$redlistCategory)
table(bag_pred, mammal_test_df$redlistCategory)

colnames(mammal_train_df)[mammal_lda_variables[[10]]]

#test error 0.3117428

<<<<<<< HEAD
```

# 8: Boosted Forests

# 9: Neural Networks

## Mammal Neural Network

### Variable Selection

```{r}

mammal_nn_variables = list(c(38,4, 5, 6, 7, 8, 9, 10, 11, 12, 13), #all diet variables
                            c(38,7, 9, 10, 11, 12, 13),                  #selected diet variables
                            c(38,41),                               #log body mass
                            c(38,19, 20, 21, 41),                   #activity and body mass
                            c(38,4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 20, 21), #all diet and activity variables
                            c(38,4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 41),         #all diet and body mass
                            c(38,41, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 20, 21), #all diet and activity and body mass
                            c(38,7, 9, 10, 11, 12, 13, 41), #selected activity variables and body mass
                            c(38,7, 9, 10, 11, 12, 13, 19, 20, 21), #selected diet and activity
                            c(38,7, 9, 10, 11, 12, 13, 19, 20, 21, 41), #selected diet, activity and body mass
                            c(38,42, 43, 44, 45, 46, 47, 48), # 7 PC for diet
                            c(38,42, 43, 44, 45, 46, 47, 48, 41), # PCA for diet and diet
                            c(38,42, 43, 44, 45, 46, 47, 48, 19, 20, 21), # PCA for diet and activity
                            c(38,42, 43, 44, 45, 46, 47, 48, 19, 20, 21, 41), # PCA for diet, activity, and body mass
                            c(38,7, 9, 10, 11, 12, 13, 16),     #selected diet variables and foraging
                            c(38,7, 9, 10, 11, 12, 13, 41, 16), #selected activity variables and body mass and foraging
                            c(38, 16, 19, 20, 21), # activity and foraging
                            c(38, 16, 42, 43, 44, 45, 46, 47, 48, 41),   # PCA for diet, and body mass and foraging
                            c(38, 16, 42, 43, 44, 45, 46, 47, 48, 19, 20, 21, 41), #PCAdiet, and activity, body mass, and foraging
                            c(38,7, 9, 10, 11, 12, 13, 19, 20, 21, 41, 16)#selected diet, activity and body mass and foraging
                        
                            )  
test_errors = rep(0, length(mammal_nn_variables))

for(i in 1:length(mammal_nn_variables)){
  var = mammal_nn_variables[[i]]
  mammal_nn = nnet(redlistCategory ~ .,
                   data = mammal_train_df[,var], size = 20, linout = FALSE)
  nn_pred = predict(mammal_nn, newdata=mammal_test_df[,var], type = "class")
  test_errors[i] = mean(nn_pred != mammal_test_df$redlistCategory)
}

which.min(test_errors)
mammal_nn_variables[[which.min(test_errors)]]

```

```{r}

var = mammal_nn_variables[[4]]
mammal_nn = nnet(redlistCategory ~ .,
                   data = mammal_train_df[,var], size = 20, linout = FALSE)
nn_pred = predict(mammal_nn, newdata=mammal_test_df[,var], type = "class")
mean(nn_pred != mammal_test_df$redlistCategory)

# Error rate = 0.3140

```

### Choosing Number of Hidden Units

```{r}

test_errors = rep(0, 20)

for(i in seq(5, 100, 5)){
  var = mammal_nn_variables[[4]]
  mammal_nn = nnet(redlistCategory ~ .,
                   data = mammal_train_df[,var], size = i, linout = FALSE)
  nn_pred = predict(mammal_nn, newdata=mammal_test_df[,var], type = "class")
  test_errors[i] = mean(nn_pred != mammal_test_df$redlistCategory)
}

which.min(test_errors)
seq(5, 100, 5)[[which.min(test_errors)]]

```

### Best Model

```{r}

var = mammal_nn_variables[[4]]
mammal_nn = nnet(redlistCategory ~ .,
                   data = mammal_train_df[,var], size = 5, linout = FALSE)
nn_pred = predict(mammal_nn, newdata=mammal_test_df[,var], type = "class")
mean(nn_pred != mammal_test_df$redlistCategory)

# Error rate = 0.312

```

## Bird Neural Network

### Variable Selection

```{r}

bird_train_df = bird_train_df %>% 
  mutate(redlistCategory = as.factor(redlistCategory))

bird_test_df = bird_test_df %>% 
  mutate(redlistCategory = as.factor(redlistCategory))

bird_nn_variables = list(c(54, 12:21), # all diet variables
                         c(54, 37,57), # activity and body mass
                         c(54, 12:21, 37), # all diet and activity variables
                         c(54, 12:21, 57), # all diet and body mass
                         c(54, 12:21, 37, 57), # all diet and activity and body mass
                         c(54, 26:33), # foraging variables
                         c(54, 26:33, 12:21), # diet and foraging
                         c(54, 26:33, 57), # foraging and body mass
                         c(54, 26:33, 12:21, 37, 57), 
                          # foraging, body mass, activity, and diet
                         c(54, 75:91), # PCA for diet and foraing together
                         c(54, 75:91, 57), 
                          # PCA for diet and foraging together and body mass
                         c(54, 75:91, 57, 37)
                          # PCA for diet + foraging, activity, and body mass
                        )
test_errors = rep(0, length(bird_nn_variables))

for(i in 1:length(bird_nn_variables)){
  var = bird_nn_variables[[i]]
  bird_nn = nnet(redlistCategory ~ .,
                   data = bird_train_df[,var], size = 20, linout = FALSE)
  nn_pred = predict(bird_nn, newdata=bird_test_df[,var], type = "class")
  test_errors[i] = mean(nn_pred != bird_test_df$redlistCategory)
}

which.min(test_errors)
bird_nn_variables[[which.min(test_errors)]]

```

```{r}

var = bird_nn_variables[[4]]
bird_nn = nnet(redlistCategory ~ .,
                   data = bird_train_df[,var], size = 20, linout = FALSE)
nn_pred = predict(bird_nn, newdata=bird_test_df[,var], type = "class")
mean(nn_pred != bird_test_df$redlistCategory)

# Error rate = 0.228

```

### Choosing Number of Hidden Units

```{r}

test_errors = rep(0, 10)

for(i in seq(5, 50, 5)){
  var = bird_nn_variables[[4]]
  bird_nn = nnet(redlistCategory ~ .,
                   data = bird_train_df[,var], size = i, linout = FALSE)
  nn_pred = predict(bird_nn, newdata=bird_test_df[,var], type = "class")
  test_errors[i] = mean(nn_pred != bird_test_df$redlistCategory)
}

which.min(test_errors)
seq(5, 70, 5)[[which.min(test_errors)]]

```

### Best Model

```{r}

var = bird_nn_variables[[4]]
bird_nn = nnet(redlistCategory ~ .,
                   data = bird_train_df[,var], size = 5, linout = FALSE)
nn_pred = predict(bird_nn, newdata=bird_test_df[,var], type = "class")
mean(nn_pred != bird_test_df$redlistCategory)

# Error rate = 0.222

```

=======
## Bird Random Forest




# 8: Boosted Forests

## Mammal Boosted Forest

### Variable Selection
>>>>>>> 33f3e94aaa1f5140099f1a5c3543a03f2a520202

```{r}

#Using variables selected for LDA
test_errors = rep(0, length(mammal_lda_variables)*5)


set.seed(10)
for(i in 1:length(mammal_lda_variables)){
  var = mammal_lda_variables[[i]]
  
  if(i==3) next
  
  for (ii in 1:5) {
  mammal_boost = gbm(as.factor(redlistCategory) ~ .,
                      data=mammal_train_df[,var],n.trees=1000,distribution = "multinomial",
                     interaction.depth=4,shrinkage = c(0.1,0.01,0.001,0.0001)[ii])
  pred_tmp = predict(mammal_boost,newdata = mammal_test_df[,var],n.trees = 1000)
  tmp_max = apply(pred_tmp, 1, which.max)
  pred_boosted=c("Endangered","Least Concern", "Near Threatened","Vulnerable")[tmp_max]

  iii=(i-1)*5+ii
  
  test_errors[iii] = mean(pred_boosted!= mammal_test_df$redlistCategory)
}
  
}

test_errors[test_errors==0]=1

which.min(test_errors)
mammal_lda_variables[[
  ceiling(which.min(test_errors)/5)
  ]]
#shrinkage
c(0.1,0.01,0.001,0.0001,0.00001)[which.min(test_errors)%%5]

mammal_lda_variables[[3]]

```

### Best Model

## Bird Boosted Forest

### Variable Selection

### Best Model


# 10: Support Vector Machines


## Mammal Boosted Forest

### Variable Selection

#### Using a Linear Function

```{r}
#Using variables selected for LDA
test_errors = rep(0, length(mammal_lda_variables)*5)

best_params = data.frame(cost = rep(0, length(mammal_lda_variables)*5),
                         gamma=rep(0, length(mammal_lda_variables)*5))

set.seed(10)
for(i in 1:length(mammal_lda_variables)){
  var = mammal_lda_variables[[i]]
  
  if(i==3) next
  
  mammal_svm = tune(svm, as.factor(redlistCategory)∼., 
                  data=mammal_train_df[,var],kernel="linear",
                  ranges=list(cost=c(0.1,1,10),
                  gamma=c(0.5,1,2,3,4)))
    
  best_params[i] = mammal_svm$best.parameters
  test_errors[i] = mean(dat[-train ,"y"] != predict(tune.out$best.model,newdata=dat[-train ,]))
    
  

  
}

which.min(test_errors)
mammal_lda_variables[[which.min(test_errors)]]
best_params[which.min(test_errors),]



```

#### Using a Polynomial Function

```{r}
#Using variables selected for LDA
test_errors = rep(0, length(mammal_lda_variables)*5)

best_params = data.frame(cost = rep(0, length(mammal_lda_variables)*5),
                         gamma=rep(0, length(mammal_lda_variables)*5))

set.seed(10)
for(i in 1:length(mammal_lda_variables)){
  var = mammal_lda_variables[[i]]
  
  if(i==3) next
  
  mammal_svm = tune(svm, as.factor(redlistCategory)∼., 
                  data=mammal_train_df[,var],kernel="polynomial",
                  ranges=list(cost=c(0.1,1,10),
                  gamma=c(0.5,1,2,3,4)))
    
  best_params[i] = mammal_svm$best.parameters
  test_errors[i] = mean(dat[-train ,"y"] != predict(tune.out$best.model,newdata=dat[-train ,]))
    
  

  
}

which.min(test_errors)
mammal_lda_variables[[which.min(test_errors)]]
best_params[which.min(test_errors),]
```


#### Using a Radial Function
```{r}
#Using variables selected for LDA
test_errors = rep(0, length(mammal_lda_variables)*5)

best_params = data.frame(cost = rep(0, length(mammal_lda_variables)*5),
                         gamma=rep(0, length(mammal_lda_variables)*5))

set.seed(10)
for(i in 1:length(mammal_lda_variables)){
  var = mammal_lda_variables[[i]]
  
  if(i==3) next
  
  mammal_svm = tune(svm, as.factor(redlistCategory)∼., 
                  data=mammal_train_df[,var],kernel="radial",
                  ranges=list(cost=c(0.1,1,10),
                  gamma=c(0.5,1,2,3,4)))
    
  best_params[i] = mammal_svm$best.parameters
  test_errors[i] = mean(dat[-train ,"y"] != predict(tune.out$best.model,newdata=dat[-train ,]))
    
  

  
}

which.min(test_errors)
mammal_lda_variables[[which.min(test_errors)]]
best_params[which.min(test_errors),]
```


### Best Model

## Bird Boosted Forest


### Variable Selection


#### Using a Linear Function

```{r}
#Using variables selected for LDA
test_errors = rep(0, length(bird_lda_variables)*5)

best_params = data.frame(cost = rep(0, length(bird_lda_variables)*5),
                         gamma=rep(0, length(bird_lda_variables)*5))

set.seed(10)
for(i in 1:length(bird_lda_variables)){
  var = bird_lda_variables[[i]]
  
  if(i==3) next
  
  bird_svm = tune(svm, as.factor(redlistCategory)∼., 
                  data=bird_train_df[,var],kernel="linear",
                  ranges=list(cost=c(0.1,1,10),
                  gamma=c(0.5,1,2,3,4)))
    
  best_params[i] = bird_svm$best.parameters
  test_errors[i] = mean(dat[-train ,"y"] != predict(tune.out$best.model,newdata=dat[-train ,]))
    
  

  
}

which.min(test_errors)
bird_lda_variables[[which.min(test_errors)]]
best_params[which.min(test_errors),]



```

#### Using a Polynomial Function

```{r}
#Using variables selected for LDA
test_errors = rep(0, length(bird_lda_variables)*5)

best_params = data.frame(cost = rep(0, length(bird_lda_variables)*5),
                         gamma=rep(0, length(bird_lda_variables)*5))

set.seed(10)
for(i in 1:length(bird_lda_variables)){
  var = bird_lda_variables[[i]]
  
  if(i==3) next
  
  bird_svm = tune(svm, as.factor(redlistCategory)∼., 
                  data=bird_train_df[,var],kernel="polynomial",
                  ranges=list(cost=c(0.1,1,10),
                  gamma=c(0.5,1,2,3,4)))
    
  best_params[i] = bird_svm$best.parameters
  test_errors[i] = mean(dat[-train ,"y"] != predict(tune.out$best.model,newdata=dat[-train ,]))
    
  

  
}

which.min(test_errors)
bird_lda_variables[[which.min(test_errors)]]
best_params[which.min(test_errors),]
```


#### Using a Radial Function
```{r}
#Using variables selected for LDA
test_errors = rep(0, length(bird_lda_variables)*5)

best_params = data.frame(cost = rep(0, length(bird_lda_variables)*5),
                         gamma=rep(0, length(bird_lda_variables)*5))

set.seed(10)
for(i in 1:length(bird_lda_variables)){
  var = bird_lda_variables[[i]]
  
  if(i==3) next
  
  bird_svm = tune(svm, as.factor(redlistCategory)∼., 
                  data=bird_train_df[,var],kernel="radial",
                  ranges=list(cost=c(0.1,1,10),
                  gamma=c(0.5,1,2,3,4)))
    
  best_params[i] = bird_svm$best.parameters
  test_errors[i] = mean(dat[-train ,"y"] != predict(tune.out$best.model,newdata=dat[-train ,]))
    
  

  
}

which.min(test_errors)
bird_lda_variables[[which.min(test_errors)]]
best_params[which.min(test_errors),]
```

### Best Model





